# M√≥dulo 1: Fundamentos de LangGraph y Sistemas Ag√©nticos

## √çndice
1. [Introducci√≥n](#introducci√≥n)
2. [Workflows vs Agentes](#workflows-vs-agentes)
3. [Componentes de LangGraph](#componentes-de-langgraph)
4. [Anatom√≠a de un Sistema Ag√©ntico](#anatom√≠a-de-un-sistema-ag√©ntico)
5. [El Pattern ReAct](#el-pattern-react)
6. [Cu√°ndo Usar Cada Enfoque](#cu√°ndo-usar-cada-enfoque)
7. [Referencias](#referencias)

---

## Introducci√≥n

Los **sistemas basados en LLMs** (Large Language Models) han evolucionado significativamente desde simples prompts hasta arquitecturas complejas que combinan razonamiento, herramientas y memoria. Este m√≥dulo establece los fundamentos para entender y construir estos sistemas usando **LangGraph**, un framework dise√±ado espec√≠ficamente para orquestar aplicaciones con LLMs.

### ¬øPor qu√© LangGraph?

LangGraph resuelve problemas fundamentales al construir sistemas con LLMs:

1. **Orquestaci√≥n Expl√≠cita**: Define flujos de control como grafos (DAGs o c√≠clicos)
2. **Estado Compartido**: Gestiona el estado a trav√©s de m√∫ltiples pasos
3. **Flexibilidad**: Soporta desde workflows simples hasta agentes aut√≥nomos complejos
4. **Observabilidad**: Integraci√≥n nativa con LangSmith para debugging
5. **Producci√≥n-Ready**: Checkpointing, persistencia y manejo de errores

---

## Workflows vs Agentes

La distinci√≥n fundamental en sistemas con LLMs es entre **workflows determin√≠sticos** y **agentes aut√≥nomos**.

### Workflows Determin√≠sticos

Un workflow es una secuencia predefinida de operaciones que se ejecutan en un orden espec√≠fico.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Input   ‚îÇ -> ‚îÇ  Step 1  ‚îÇ -> ‚îÇ  Step 2  ‚îÇ -> ‚îÇ  Output  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caracter√≠sticas:**
- ‚úÖ **Predecible**: Siempre sigue el mismo camino
- ‚úÖ **F√°cil de debuggear**: El flujo es expl√≠cito
- ‚úÖ **Menor costo**: Menos llamadas al LLM
- ‚úÖ **R√°pido**: No hay decisiones que tomar
- ‚ùå **Inflexible**: No se adapta a cambios en el input

**Ejemplo de uso:**
- Pipelines de ETL (Extract, Transform, Load)
- Procesamiento de documentos multi-etapa
- Validaci√≥n de datos secuencial
- Generaci√≥n de reportes estructurados

**C√≥digo conceptual:**
```python
def workflow(input):
    result1 = step1(input)
    result2 = step2(result1)
    result3 = step3(result2)
    return result3
```

### Agentes Aut√≥nomos

Un agente es un sistema que **decide din√°micamente** qu√© hacer en cada paso bas√°ndose en el contexto.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Input   ‚îÇ -> ‚îÇ  LLM Decide  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚ñº                     ‚ñº
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ  Tool A  ‚îÇ          ‚îÇ  Tool B  ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ                     ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚ñº
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ  LLM Decide  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> ¬øContinuar?
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caracter√≠sticas:**
- ‚úÖ **Flexible**: Se adapta a diferentes inputs
- ‚úÖ **Aut√≥nomo**: Toma decisiones sin programaci√≥n expl√≠cita
- ‚úÖ **Robusto**: Puede manejar casos no previstos
- ‚ùå **Impredecible**: El camino var√≠a seg√∫n el contexto
- ‚ùå **M√°s costoso**: M√∫ltiples llamadas al LLM
- ‚ùå **M√°s lento**: Cada decisi√≥n toma tiempo

**Ejemplo de uso:**
- Asistentes conversacionales
- Sistemas de investigaci√≥n aut√≥nomos
- Resoluci√≥n de problemas complejos
- Interfaces de lenguaje natural para APIs

**C√≥digo conceptual:**
```python
def agent(input):
    state = {"input": input, "done": False}
    while not state["done"]:
        action = llm_decide(state)
        result = execute_action(action)
        state = update_state(state, result)
    return state["output"]
```

### Comparaci√≥n Directa

| Aspecto | Workflow | Agente |
|---------|----------|--------|
| **Flujo** | Predefinido y fijo | Din√°mico y adaptativo |
| **Decisiones** | No toma decisiones | Decide en cada paso |
| **Complejidad** | Baja | Media a Alta |
| **Costo** | Bajo (menos llamadas LLM) | Alto (m√∫ltiples llamadas) |
| **Latencia** | Baja (sin decisiones) | Alta (razonamiento) |
| **Debugging** | F√°cil (flujo expl√≠cito) | Dif√≠cil (emergente) |
| **Casos de uso** | Procesos conocidos | Problemas abiertos |
| **Herramientas** | Opcionales | Esenciales |

---

## Componentes de LangGraph

LangGraph se basa en tres primitivas fundamentales:

### 1. State (Estado)

El estado es un **diccionario tipado** que fluye a trav√©s del grafo.

```python
from typing import TypedDict

class MyState(TypedDict):
    input: str
    intermediate_result: str
    output: str
```

**Caracter√≠sticas importantes:**
- Se define usando `TypedDict` para type hints
- Cada nodo puede leer cualquier campo
- Los nodos retornan solo los campos que actualizan
- LangGraph fusiona autom√°ticamente los updates

**Reducers especiales:**

```python
from typing import Annotated
from langgraph.graph.message import add_messages

class StateWithMessages(TypedDict):
    # add_messages es un reducer que agrega mensajes en lugar de reemplazarlos
    messages: Annotated[list[BaseMessage], add_messages]
```

### 2. Nodes (Nodos)

Los nodos son **funciones** que transforman el estado.

```python
def my_node(state: MyState) -> dict:
    """
    Un nodo recibe el estado y retorna un diccionario
    con los campos a actualizar.
    """
    # Leer del estado
    input_data = state["input"]

    # Procesar (llamar LLM, usar herramienta, etc.)
    result = process(input_data)

    # Retornar solo campos actualizados
    return {"intermediate_result": result}
```

**Tipos de nodos comunes:**

1. **Nodos de procesamiento**: Transforman datos
2. **Nodos de LLM**: Invocan modelos de lenguaje
3. **Nodos de herramientas**: Ejecutan tools
4. **Nodos de decisi√≥n**: Clasifican o rutean

### 3. Graph (Grafo)

El grafo conecta nodos en un flujo de ejecuci√≥n.

```python
from langgraph.graph import StateGraph, END

# Crear grafo
workflow = StateGraph(MyState)

# Agregar nodos
workflow.add_node("node1", my_node_function)
workflow.add_node("node2", another_node_function)

# Definir flujo
workflow.set_entry_point("node1")
workflow.add_edge("node1", "node2")
workflow.add_edge("node2", END)

# Compilar
app = workflow.compile()
```

### 4. Edges (Conexiones)

Existen dos tipos de edges:

#### a) **Edges Incondicionales**
Siempre siguen el mismo camino.

```python
workflow.add_edge("node_a", "node_b")
```

#### b) **Conditional Edges**
Deciden din√°micamente el siguiente nodo.

```python
def router(state: MyState) -> str:
    """Funci√≥n que decide el siguiente nodo"""
    if state["some_condition"]:
        return "path_a"
    else:
        return "path_b"

workflow.add_conditional_edges(
    "decision_node",
    router,
    {
        "path_a": "node_a",
        "path_b": "node_b"
    }
)
```

---

## Anatom√≠a de un Sistema Ag√©ntico

Un sistema ag√©ntico con LLM se compone de:

### 1. LLM Aumentado

El LLM (modelo de lenguaje) es el "cerebro" del sistema.

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.7
)
```

**Par√°metros importantes:**
- `model`: El modelo a usar (gpt-4, claude-3, etc.)
- `temperature`: Aleatoriedad (0 = determinista, 1 = creativo)
- `max_tokens`: L√≠mite de tokens en la respuesta

### 2. Herramientas (Tools)

Las herramientas son **funciones que el LLM puede invocar**.

```python
from langchain_core.tools import tool

@tool
def calculator(expression: str) -> str:
    """
    Calcula expresiones matem√°ticas.

    Args:
        expression: Expresi√≥n matem√°tica (ej: "2 + 2")

    Returns:
        Resultado del c√°lculo
    """
    return str(eval(expression))
```

**Importante:**
- El docstring es crucial: el LLM lo usa para decidir cu√°ndo usar la tool
- Los type hints definen el esquema de entrada
- El nombre de la funci√≥n es c√≥mo el LLM la invoca

**Vincular tools al LLM:**

```python
tools = [calculator, search, other_tool]
llm_with_tools = llm.bind_tools(tools)
```

### 3. Memoria (State Management)

La memoria permite al sistema recordar informaci√≥n entre pasos.

```python
from typing import Annotated, Sequence
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages

class AgentState(TypedDict):
    # Los mensajes se acumulan (no se reemplazan)
    messages: Annotated[Sequence[BaseMessage], add_messages]
```

**Tipos de memoria:**

1. **Short-term (Working memory)**: El estado del grafo
2. **Long-term**: Persistencia entre sesiones (checkpoints)
3. **Semantic**: RAG (Retrieval-Augmented Generation)

### 4. Ciclo de Control

El ciclo que orquesta el sistema.

```python
def build_agent_graph():
    workflow = StateGraph(AgentState)

    # Nodo que razona y decide
    workflow.add_node("agent", agent_node)

    # Nodo que ejecuta herramientas
    workflow.add_node("tools", tool_node)

    # Ciclo: agent -> tools -> agent
    workflow.set_entry_point("agent")
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {"continue": "tools", "end": END}
    )
    workflow.add_edge("tools", "agent")

    return workflow.compile()
```

---

## El Pattern ReAct

**ReAct** (Reasoning + Acting) es el patr√≥n fundamental para agentes con LLMs.

### Ciclo ReAct

```
1. REASON (Razonar)
   ‚Üì
   "Necesito saber X para responder"
   ‚Üì
2. ACT (Actuar)
   ‚Üì
   Llamar herramienta con par√°metros
   ‚Üì
3. OBSERVE (Observar)
   ‚Üì
   Ver resultado de la herramienta
   ‚Üì
   ¬øTengo suficiente informaci√≥n?
   NO ‚Üí Volver a REASON
   S√ç ‚Üí RESPOND (Responder)
```

### Ejemplo de Trace ReAct

```
Usuario: "¬øCu√°l es el 15% de 250 m√°s el precio del producto X?"

[1] REASON
Agente: "Necesito calcular 15% de 250 y buscar el precio del producto X"

[2] ACT
Agente: tool_calls=[
    {"name": "calculator", "args": {"expression": "15% of 250"}}
]

[3] OBSERVE
Tool: "37.5"

[4] REASON (contin√∫a)
Agente: "Ahora necesito el precio del producto X"

[5] ACT
Agente: tool_calls=[
    {"name": "search_knowledge", "args": {"query": "precio producto X"}}
]

[6] OBSERVE
Tool: "El precio del producto X es $120"

[7] REASON (final)
Agente: "Tengo ambas piezas, puedo calcular el total"

[8] ACT
Agente: tool_calls=[
    {"name": "calculator", "args": {"expression": "37.5 + 120"}}
]

[9] OBSERVE
Tool: "157.5"

[10] RESPOND
Agente: "El resultado es $157.5 (15% de 250 = $37.5, m√°s el precio del
         producto X = $120)"
```

### Implementaci√≥n en LangGraph

```python
def agent_node(state: AgentState):
    """Nodo que implementa REASON y decide ACT"""
    messages = state["messages"]
    response = llm_with_tools.invoke(messages)
    return {"messages": [response]}

def tool_node(state: AgentState):
    """Nodo que implementa ACT y OBSERVE"""
    last_message = state["messages"][-1]
    tool_calls = last_message.tool_calls

    tool_messages = []
    for call in tool_calls:
        result = execute_tool(call)
        tool_messages.append(ToolMessage(result, call["id"]))

    return {"messages": tool_messages}

def should_continue(state: AgentState):
    """Decide si continuar el ciclo o terminar"""
    last_message = state["messages"][-1]
    if last_message.tool_calls:
        return "continue"  # Hay herramientas por ejecutar
    return "end"  # El agente dio una respuesta final
```

---

## Cu√°ndo Usar Cada Enfoque

### Usa Workflows Cuando:

‚úÖ **Conoces los pasos exactos**
```
Ejemplo: Pipeline de procesamiento de CV
1. Extraer texto del PDF
2. Identificar secciones
3. Extraer informaci√≥n estructurada
4. Validar contra requisitos
5. Generar reporte
```

‚úÖ **El proceso es repetitivo y predecible**
```
Ejemplo: Generaci√≥n de reportes diarios
- Los pasos siempre son los mismos
- Solo var√≠an los datos de entrada
```

‚úÖ **La eficiencia es cr√≠tica**
```
Ejemplo: Procesamiento de alto volumen
- Costo por llamada LLM es significativo
- Latencia debe ser m√≠nima
```

‚úÖ **Necesitas debugging f√°cil**
```
Ejemplo: Sistemas en producci√≥n cr√≠ticos
- F√°cil identificar d√≥nde fall√≥
- Logs claros de cada paso
```

### Usa Agentes Cuando:

‚úÖ **No conoces los pasos de antemano**
```
Ejemplo: Asistente de investigaci√≥n
- La consulta puede requerir 1, 3 o 10 pasos
- Depende de qu√© encuentre en cada b√∫squeda
```

‚úÖ **Necesitas adaptabilidad**
```
Ejemplo: Soporte t√©cnico automatizado
- Diferentes problemas requieren diferentes soluciones
- El agente debe diagnosticar y resolver
```

‚úÖ **El problema requiere razonamiento**
```
Ejemplo: An√°lisis de c√≥digo complejo
- Necesita entender el contexto
- Decidir qu√© archivos revisar
- Adaptar el an√°lisis seg√∫n lo que encuentre
```

‚úÖ **Tienes herramientas variadas**
```
Ejemplo: Asistente personal
- M√∫ltiples APIs y servicios
- El agente decide cu√°les usar y en qu√© orden
```

### Enfoque H√≠brido

En la pr√°ctica, **combinar ambos** suele ser √≥ptimo:

```python
# Workflow principal con pasos ag√©nticos

def hybrid_system():
    # PASO 1: Workflow - Clasificaci√≥n
    category = classify_query(user_input)

    # PASO 2: Agent - Resolver seg√∫n categor√≠a
    if category == "technical":
        result = technical_agent(user_input)
    elif category == "sales":
        result = sales_agent(user_input)

    # PASO 3: Workflow - Formatear respuesta
    formatted = format_response(result)

    return formatted
```

---

## Referencias

### Documentaci√≥n Oficial
- [LangGraph Overview](https://docs.langchain.com/oss/python/langgraph/overview.md)
- [LangGraph Quickstart](https://docs.langchain.com/oss/python/langgraph/quickstart.md)
- [Workflows and Agents](https://docs.langchain.com/oss/python/langgraph/workflows-agents.md)
- [Thinking in LangGraph](https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph.md)

### Papers Importantes
- **ReAct: Synergizing Reasoning and Acting in Language Models** (Yao et al., 2022)
- **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models** (Wei et al., 2022)
- **Reflexion: Language Agents with Verbal Reinforcement Learning** (Shinn et al., 2023)

### Recursos Adicionales
- [LangChain Academy](https://docs.langchain.com/oss/python/langchain/academy.md)
- [LangGraph Agents Guide](https://docs.langchain.com/oss/python/langchain/agents.md)
- [Tool Calling Documentation](https://docs.langchain.com/oss/python/langchain/tools.md)

---

## Siguiente M√≥dulo

En el **M√≥dulo 2: Patrones de Workflows Multi-Agente**, exploraremos:
- Routing y clasificaci√≥n
- Paralelizaci√≥n (sectioning y voting)
- Orchestrator-Workers pattern
- Evaluator-Optimizer pattern

¬°Contin√∫a al M√≥dulo 2 para aprender a coordinar m√∫ltiples agentes! üöÄ
