"""
Ejemplo: Debugging con LangSmith

Este ejemplo demuestra c√≥mo usar LangSmith para debugging y observabilidad
de sistemas multi-agente construidos con LangGraph.

Aprender√°s:
1. Configuraci√≥n b√°sica de LangSmith
2. Tracing autom√°tico de grafos
3. A√±adir metadata y tags personalizados
4. Debugging de decisiones de agentes
5. An√°lisis de rendimiento

Requisitos:
- Cuenta en https://smith.langchain.com (gratis)
- Variables de entorno configuradas (ver .env.example)
"""

import operator
from typing import Annotated, TypedDict, Literal
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END, START
from langgraph.prebuilt import ToolNode
from langchain_core.tools import tool

# Importar utilidades de LangSmith
from utils.langsmith_config import (
    LangSmithConfig,
    get_runnable_config,
    add_run_metadata,
    trace_section,
    log_agent_decision,
    trace_agent
)


# ============================================================================
# 1. CONFIGURACI√ìN INICIAL
# ============================================================================

def setup_langsmith():
    """
    Configura y verifica LangSmith.

    Si no est√° configurado, el c√≥digo seguir√° funcionando pero sin tracing.
    """
    config = LangSmithConfig(project_name="micai-debugging-demo")
    config.print_status()
    return config


# ============================================================================
# 2. DEFINIR HERRAMIENTAS
# ============================================================================

@tool
def search_knowledge_base(query: str) -> str:
    """
    Busca informaci√≥n en la base de conocimientos interna.
    Usa esto para: preguntas sobre productos, pol√≠ticas, procedimientos.
    """
    # Simulaci√≥n
    knowledge = {
        "precio": "El producto X cuesta $99.99",
        "politica": "Devoluciones aceptadas dentro de 30 d√≠as",
        "horario": "Atenci√≥n de 9am a 6pm, Lunes a Viernes"
    }

    for key, value in knowledge.items():
        if key in query.lower():
            return value

    return "No se encontr√≥ informaci√≥n relevante en la base de conocimientos."


@tool
def search_web(query: str) -> str:
    """
    Busca informaci√≥n en internet.
    Usa esto para: noticias actuales, informaci√≥n general, tendencias.
    """
    # Simulaci√≥n
    return f"Resultados de b√∫squeda web para: {query}"


@tool
def calculate(expression: str) -> str:
    """
    Realiza c√°lculos matem√°ticos.
    Usa esto para: operaciones aritm√©ticas, conversiones.
    """
    try:
        result = eval(expression)
        return f"Resultado: {result}"
    except Exception as e:
        return f"Error en el c√°lculo: {e}"


# ============================================================================
# 3. DEFINIR ESTADO
# ============================================================================

class AgentState(TypedDict):
    """
    Estado del agente con mensajes y metadata para debugging.
    """
    messages: Annotated[list, operator.add]
    # Campos adicionales para debugging
    decision_count: int
    tools_used: list[str]
    current_step: str


# ============================================================================
# 4. NODOS DEL GRAFO CON TRACING
# ============================================================================

@trace_agent(
    name="ClassifierNode",
    tags=["routing", "classification"],
    metadata_fn=lambda state: {
        "message_count": len(state["messages"]),
        "step": state.get("current_step", "unknown")
    }
)
def classifier_node(state: AgentState) -> AgentState:
    """
    Clasifica el tipo de consulta para enrutamiento.

    Este nodo demuestra:
    - Logging de decisiones para debugging
    - Metadata personalizada
    - Razonamiento explicito
    """
    messages = state["messages"]
    last_message = messages[-1].content.lower()

    # Usar trace_section para agrupar l√≥gica relacionada
    with trace_section("IntentClassification", tags=["ml", "classification"]):
        # Clasificaci√≥n simple basada en keywords
        if any(word in last_message for word in ["precio", "costo", "cuanto"]):
            intent = "pricing"
            confidence = 0.9
        elif any(word in last_message for word in ["pol√≠tica", "devoluci√≥n", "reembolso"]):
            intent = "policy"
            confidence = 0.85
        elif any(word in last_message for word in ["calcula", "suma", "multiplica"]):
            intent = "calculation"
            confidence = 0.95
        else:
            intent = "general"
            confidence = 0.6

    # Registrar la decisi√≥n para debugging
    log_agent_decision(
        agent_name="Classifier",
        decision=intent,
        reasoning=f"Keywords matched for {intent} category",
        confidence=confidence
    )

    # A√±adir metadata adicional
    add_run_metadata({
        "classified_intent": intent,
        "confidence_score": confidence,
        "message_length": len(last_message)
    })

    return {
        **state,
        "current_step": "classified",
        "decision_count": state.get("decision_count", 0) + 1
    }


def agent_node(state: AgentState) -> AgentState:
    """
    Agente principal que usa herramientas.

    Demuestra tracing autom√°tico de:
    - Llamadas a LLM
    - Uso de herramientas
    - Selecci√≥n de tools
    """
    tools = [search_knowledge_base, search_web, calculate]
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    llm_with_tools = llm.bind_tools(tools)

    # El system prompt es cr√≠tico para debugging
    # LangSmith te mostrar√° exactamente qu√© ve el LLM
    system_msg = SystemMessage(
        content="""Eres un asistente √∫til y preciso.

Tienes acceso a tres herramientas:
1. search_knowledge_base: Para informaci√≥n interna (productos, pol√≠ticas)
2. search_web: Para informaci√≥n externa (noticias, general)
3. calculate: Para c√°lculos matem√°ticos

Selecciona la herramienta M√ÅS APROPIADA para cada consulta.
"""
    )

    messages = [system_msg] + state["messages"]

    # Esta llamada se traza autom√°ticamente en LangSmith
    # Ver√°s: prompt completo, respuesta, tokens, latencia, costo
    response = llm_with_tools.invoke(messages)

    # Registrar qu√© herramientas se solicitaron
    if hasattr(response, 'tool_calls') and response.tool_calls:
        tool_names = [tc["name"] for tc in response.tool_calls]
        add_run_metadata({
            "tools_requested": tool_names,
            "tool_call_count": len(tool_names)
        })

        # Actualizar lista de herramientas usadas
        tools_used = state.get("tools_used", [])
        tools_used.extend(tool_names)

        return {
            **state,
            "messages": [response],
            "tools_used": tools_used,
            "current_step": "tool_called"
        }

    return {
        **state,
        "messages": [response],
        "current_step": "completed"
    }


def should_continue(state: AgentState) -> Literal["tools", "end"]:
    """
    Decide si continuar con herramientas o terminar.

    Esta funci√≥n de routing tambi√©n se traza, mostrando
    la l√≥gica de decisi√≥n en el flujo del grafo.
    """
    messages = state["messages"]
    last_message = messages[-1]

    # Logging para debugging
    has_tool_calls = hasattr(last_message, 'tool_calls') and last_message.tool_calls

    add_run_metadata({
        "routing_decision": "tools" if has_tool_calls else "end",
        "has_tool_calls": has_tool_calls,
        "message_type": type(last_message).__name__
    })

    if has_tool_calls:
        return "tools"
    return "end"


# ============================================================================
# 5. CONSTRUIR GRAFO
# ============================================================================

def create_debugging_graph():
    """
    Crea un grafo con nodos que demuestran diferentes aspectos de debugging.
    """
    # Crear grafo
    workflow = StateGraph(AgentState)

    # A√±adir nodos
    workflow.add_node("classifier", classifier_node)
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", ToolNode([search_knowledge_base, search_web, calculate]))

    # Definir flujo
    workflow.add_edge(START, "classifier")
    workflow.add_edge("classifier", "agent")
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "tools": "tools",
            "end": END
        }
    )
    workflow.add_edge("tools", "agent")

    return workflow.compile()


# ============================================================================
# 6. FUNCI√ìN PRINCIPAL CON EJEMPLOS
# ============================================================================

def run_example(query: str, example_name: str):
    """
    Ejecuta un ejemplo con configuraci√≥n de LangSmith apropiada.

    Args:
        query: La consulta a procesar
        example_name: Nombre del ejemplo (para tags y metadata)
    """
    print(f"\n{'='*70}")
    print(f"Ejemplo: {example_name}")
    print(f"Query: {query}")
    print(f"{'='*70}\n")

    # Crear configuraci√≥n con tags y metadata
    config = get_runnable_config(
        tags=["example", example_name.lower().replace(" ", "-")],
        metadata={
            "example_name": example_name,
            "query": query,
            "demo": True
        },
        run_name=f"DebuggingExample_{example_name.replace(' ', '')}"
    )

    # Estado inicial
    initial_state: AgentState = {
        "messages": [HumanMessage(content=query)],
        "decision_count": 0,
        "tools_used": [],
        "current_step": "started"
    }

    # Ejecutar grafo
    graph = create_debugging_graph()
    result = graph.invoke(initial_state, config=config)

    # Mostrar resultados
    final_message = result["messages"][-1]
    print(f"‚úì Respuesta: {final_message.content}")
    print(f"‚úì Decisiones tomadas: {result['decision_count']}")
    print(f"‚úì Herramientas usadas: {result.get('tools_used', [])}")

    return result


def demonstrate_debugging_scenarios():
    """
    Demuestra diferentes escenarios de debugging.
    """
    scenarios = [
        {
            "name": "B√∫squeda de Precio",
            "query": "¬øCu√°l es el precio del producto X?",
            "expected_tool": "search_knowledge_base",
            "debugging_focus": "Verificar que se selecciona la herramienta correcta"
        },
        {
            "name": "C√°lculo Simple",
            "query": "Calcula 25 * 4 + 10",
            "expected_tool": "calculate",
            "debugging_focus": "Verificar ejecuci√≥n de herramienta matem√°tica"
        },
        {
            "name": "Consulta General",
            "query": "¬øQu√© es la inteligencia artificial?",
            "expected_tool": "search_web",
            "debugging_focus": "Verificar routing a b√∫squeda web"
        },
        {
            "name": "Pregunta Ambigua",
            "query": "Hola, ¬øc√≥mo est√°s?",
            "expected_tool": None,
            "debugging_focus": "Verificar manejo de consultas sin herramientas"
        }
    ]

    print("\n" + "="*70)
    print("üîç DEMOSTRACION DE DEBUGGING CON LANGSMITH")
    print("="*70)
    print("\nEn cada ejemplo, ve a LangSmith para analizar:")
    print("1. ¬øQu√© herramienta seleccion√≥ el agente?")
    print("2. ¬øCu√°l fue el prompt exacto enviado al LLM?")
    print("3. ¬øCu√°nto tiempo tom√≥ cada paso?")
    print("4. ¬øCu√°ntos tokens y cu√°nto cost√≥?")
    print("5. ¬øCu√°l fue el flujo completo del grafo?")

    results = []
    for scenario in scenarios:
        print(f"\nüìç Focus de debugging: {scenario['debugging_focus']}")
        result = run_example(scenario["query"], scenario["name"])
        results.append(result)

    return results


# ============================================================================
# 7. EJEMPLO DE ANALISIS POST-EJECUCION
# ============================================================================

def analyze_performance():
    """
    Demuestra c√≥mo analizar performance despu√©s de ejecutar.

    Nota: Para an√°lisis completo, usa la UI de LangSmith.
    Este es un ejemplo simplificado.
    """
    print("\n" + "="*70)
    print("üìä AN√ÅLISIS DE PERFORMANCE")
    print("="*70)

    print("""
Para an√°lisis detallado, ve a LangSmith y:

1. Filtra por tag:example
2. Compara latencias entre diferentes consultas
3. Identifica cu√°l fue m√°s costosa (tokens/dinero)
4. Busca patrones en selecci√≥n de herramientas
5. Identifica oportunidades de optimizaci√≥n

M√©tricas clave a revisar:
- Latencia total por query
- Tiempo en LLM vs tiempo en herramientas
- N√∫mero de llamadas a LLM
- Tokens promedio por consulta
- Costo total

Preguntas para investigar:
- ¬øAlguna query fue inusualmente lenta?
- ¬øEl agente siempre selecciona la herramienta correcta?
- ¬øHay llamadas redundantes al LLM?
- ¬øSe puede cachear alg√∫n resultado?
""")


# ============================================================================
# 8. MAIN
# ============================================================================

if __name__ == "__main__":
    # Verificar configuraci√≥n de LangSmith
    langsmith_config = setup_langsmith()

    if not langsmith_config.is_enabled():
        print("\n‚ö†Ô∏è WARNING: LangSmith no est√° habilitado.")
        print("El c√≥digo funcionar√°, pero no habr√° tracing.\n")
        print("Para habilitar:")
        print("1. Crea cuenta en https://smith.langchain.com")
        print("2. Configura variables en .env:")
        print("   LANGCHAIN_TRACING_V2=true")
        print("   LANGCHAIN_API_KEY=ls__your_key")
        print("   LANGCHAIN_PROJECT=micai-debugging-demo\n")

        response = input("¬øContinuar sin tracing? (y/n): ")
        if response.lower() != 'y':
            print("Abortando. Configura LangSmith primero.")
            exit(0)

    # Ejecutar ejemplos
    results = demonstrate_debugging_scenarios()

    # Mostrar an√°lisis
    analyze_performance()

    # Mensaje final
    print("\n" + "="*70)
    print("‚úÖ EJEMPLOS COMPLETADOS")
    print("="*70)

    if langsmith_config.is_enabled():
        print(f"\nüìä Ve los traces completos en:")
        print(f"   {langsmith_config.get_project_url()}")
        print("\nEn la UI de LangSmith podr√°s:")
        print("- Ver el flujo completo del grafo (nodos y edges)")
        print("- Inspeccionar cada llamada al LLM")
        print("- Comparar diferentes ejecuciones")
        print("- Identificar errores y cuellos de botella")
        print("- Analizar costos y optimizar")

    print("\nüí° Pr√≥ximos pasos:")
    print("1. Modifica las consultas y observa cambios en LangSmith")
    print("2. A√±ade m√°s herramientas y verifica selecci√≥n correcta")
    print("3. Introduce errores intencionales y debuggea")
    print("4. Experimenta con diferentes modelos LLM")
    print("5. Lee docs/05_debugging_langsmith.md para t√©cnicas avanzadas")
    print("="*70 + "\n")
