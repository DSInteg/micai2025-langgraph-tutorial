"""
Script para generar TODOS los notebooks del instructor (MÃ³dulos 2, 3, 4).

Este script crea los 12 notebooks restantes con estructura completa.
"""

import json
import os

def create_notebook_template(title, module, exercise_num, time, objectives, cells_content):
    """Crea un notebook con estructura estÃ¡ndar"""

    notebook = {
        "cells": [
            # Cell 1: Header
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    f"# {title}\n\n",
                    f"**{module}**  \n",
                    f"**Tiempo estimado**: {time}  \n",
                    f"**Ejercicio**: {exercise_num}\n\n",
                    "---\n\n",
                    "## ğŸ¯ Objetivos de Aprendizaje\n\n"
                ] + [f"{i+1}. âœ… {obj}\n" for i, obj in enumerate(objectives)]
            },
            # Cell 2: Setup
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
                    "# â•‘  ğŸ“‹ SETUP Y VERIFICACIÃ“N                                  â•‘\n",
                    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n",
                    "%pip install -q langgraph langchain-openai python-dotenv\n\n",
                    "import os, sys\n",
                    "from dotenv import load_dotenv\n",
                    "sys.path.append(os.path.abspath('../..'))\n",
                    "load_dotenv()\n\n",
                    "print('='*50)\n",
                    "print('   SETUP VERIFICATION')\n",
                    "print('='*50)\n",
                    "print(f\"âœ… Python {sys.version.split()[0]}\")\n",
                    "print(f\"{'âœ…' if os.getenv('OPENAI_API_KEY') else 'âŒ'} OpenAI API Key\")\n",
                    "print(f\"\\nğŸ¬ Ready!\\n\")"
                ]
            }
        ] + cells_content + [
            # Final cell
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "---\n\n",
                    "## âœ… CHECKPOINT FINAL\n\n",
                    "- [ ] CÃ³digo ejecuta sin errores\n",
                    "- [ ] Conceptos clave entendidos\n",
                    "- [ ] Listos para continuar\n\n",
                    "### ğŸ’¬ PREGUNTA:\n",
                    "> \"Â¿Alguna duda antes de continuar?\"\n"
                ]
            }
        ],
        "metadata": {
            "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
            "language_info": {
                "codemirror_mode": {"name": "ipython", "version": 3},
                "file_extension": ".py",
                "mimetype": "text/x-python",
                "name": "python",
                "version": "3.11.0"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }

    return notebook

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEFINICIÃ“N DE TODOS LOS NOTEBOOKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

notebooks_to_create = [
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # MÃ“DULO 2: PATRONES MULTI-AGENTE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    {
        "path": "modulo_2/01_instructor_patrones_overview.ipynb",
        "title": "ğŸ”€ Patrones Multi-Agente - Overview",
        "module": "MÃ³dulo 2: Patrones Multi-Agente",
        "exercise": "Overview",
        "time": "15 minutos",
        "objectives": [
            "Entender los 3 patterns fundamentales",
            "Routing (especializaciÃ³n)",
            "Parallelization (velocidad)",
            "Orchestrator (coordinaciÃ³n)"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"MÃ³dulo 2: Sistemas multi-agente.\n> En producciÃ³n, un solo agente no es suficiente.\n> Hoy: 3 patterns que se usan REALMENTE en empresas.\""},
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ“Š Los 3 Patterns\n\n### 1. ROUTING (EspecializaciÃ³n)\n```\nQuery â†’ Classifier â†’ Specialist\n```\n\n### 2. PARALLELIZATION (Velocidad)\n```\nInput â†’ [Agent A, Agent B, Agent C] â†’ Aggregator\n```\n\n### 3. ORCHESTRATOR (CoordinaciÃ³n)\n```\nOrchestrator â†’ Worker 1 â†’ Worker 2 â†’ Synthesis\n```"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Demo rÃ¡pida de cada pattern\n\nfrom langgraph.graph import StateGraph, START, END\nfrom typing import TypedDict\n\nprint('ğŸ”€ Vamos a ver cada uno en acciÃ³n...')\nprint('\\n1. ROUTING: Especialistas por dominio')\nprint('2. PARALLELIZATION: MÃºltiples perspectivas')\nprint('3. ORCHESTRATOR: CoordinaciÃ³n inteligente')"}
        ]
    },
    {
        "path": "modulo_2/02_instructor_ejercicio_2_1_routing.ipynb",
        "title": "ğŸ¯ Ejercicio 2.1: Sistema de Routing",
        "module": "MÃ³dulo 2: Patrones Multi-Agente",
        "exercise": "2.1",
        "time": "15 minutos",
        "objectives": [
            "Implementar classifier con LLM",
            "Crear agentes especializados",
            "Usar conditional_edges para routing",
            "Manejar mÃºltiples rutas"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"Ejercicio 2.1: Sistema de customer support con especialistas.\n> El classifier decide: Â¿technical, billing, o general?\""},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "from typing import TypedDict\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END\n\nclass SupportState(TypedDict):\n    query: str\n    intent: str\n    response: str\n\nllm = ChatOpenAI(model='gpt-4o-mini')\nprint('âœ… Setup completo')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Classifier - LA CLAVE del routing\n\ndef classify_intent(state):\n    prompt = f'''Clasifica esta consulta de soporte:\n    \n    Query: {state[\"query\"]}\n    \n    CategorÃ­as:\n    - technical: problemas de API, cÃ³digo, errores\n    - billing: pagos, facturas, suscripciones\n    - general: otras preguntas\n    \n    Responde SOLO: technical, billing, o general'''\n    \n    response = llm.invoke(prompt)\n    intent = response.content.strip().lower()\n    print(f'ğŸ¯ Clasificado como: {intent}')\n    return {'intent': intent}\n\nprint('âœ… Classifier definido')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Agentes especializados\n\ndef technical_agent(state):\n    print('ğŸ”§ Agente tÃ©cnico manejando...')\n    response = llm.invoke(f'Responde como experto tÃ©cnico: {state[\"query\"]}')\n    return {'response': response.content}\n\ndef billing_agent(state):\n    print('ğŸ’° Agente de billing manejando...')\n    response = llm.invoke(f'Responde como experto en facturaciÃ³n: {state[\"query\"]}')\n    return {'response': response.content}\n\ndef general_agent(state):\n    print('ğŸ’¬ Agente general manejando...')\n    response = llm.invoke(f'Responde de forma general: {state[\"query\"]}')\n    return {'response': response.content}\n\nprint('âœ… Agentes especializados definidos')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Construir grafo con routing\n\ngraph = StateGraph(SupportState)\n\n# Agregar nodos\ngraph.add_node('classifier', classify_intent)\ngraph.add_node('technical', technical_agent)\ngraph.add_node('billing', billing_agent)\ngraph.add_node('general', general_agent)\n\n# Routing desde classifier\ngraph.add_edge(START, 'classifier')\ngraph.add_conditional_edges(\n    'classifier',\n    lambda s: s['intent'],  # â† DecisiÃ³n basada en intent\n    {\n        'technical': 'technical',\n        'billing': 'billing',\n        'general': 'general'\n    }\n)\n\n# Todos terminan en END\ngraph.add_edge('technical', END)\ngraph.add_edge('billing', END)\ngraph.add_edge('general', END)\n\napp = graph.compile()\nprint('âœ… Sistema de routing compilado')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# ğŸ¬ DEMO: Diferentes tipos de consultas\n\ntest_queries = [\n    'Mi API da error 500',\n    'Quiero cancelar mi suscripciÃ³n',\n    'Â¿QuÃ© es LangGraph?'\n]\n\nfor query in test_queries:\n    print('='*60)\n    print(f'Query: {query}')\n    result = app.invoke({'query': query})\n    print(f'Intent: {result[\"intent\"]}')\n    print(f'Response: {result[\"response\"][:100]}...')\n    print()"}
        ]
    },
    {
        "path": "modulo_2/03_instructor_ejercicio_2_2_parallel.ipynb",
        "title": "âš¡ Ejercicio 2.2: ParalelizaciÃ³n",
        "module": "MÃ³dulo 2: Patrones Multi-Agente",
        "exercise": "2.2",
        "time": "12 minutos",
        "objectives": [
            "Usar Send() API para fan-out",
            "Ejecutar agentes en paralelo",
            "Agregar resultados de mÃºltiples agentes",
            "Medir mejoras de performance"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"Ejercicio 2.2: AnÃ¡lisis paralelo.\n> 3 analistas trabajan AL MISMO TIEMPO.\n> Esto es MUCHO mÃ¡s rÃ¡pido que secuencial.\""},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "from typing import TypedDict\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.constants import Send\n\nclass AnalysisState(TypedDict):\n    document: str\n    sentiment: str\n    entities: list\n    summary: str\n    final_report: str\n\nllm = ChatOpenAI(model='gpt-4o-mini')\nprint('âœ… Setup')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Analistas paralelos\n\ndef sentiment_analyst(state):\n    print('ğŸ­ Analizando sentimiento...')\n    result = llm.invoke(f'Sentimiento (Positivo/Negativo/Neutral): {state[\"document\"][:200]}')\n    return {'sentiment': result.content}\n\ndef entity_analyst(state):\n    print('ğŸ‘¤ Extrayendo entidades...')\n    result = llm.invoke(f'Extrae personas y organizaciones de: {state[\"document\"][:200]}')\n    return {'entities': result.content.split(',')}\n\ndef summary_analyst(state):\n    print('ğŸ“ Generando resumen...')\n    result = llm.invoke(f'Resume en una oraciÃ³n: {state[\"document\"][:200]}')\n    return {'summary': result.content}\n\nprint('âœ… Analistas definidos')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Fan-out paralelo\n\ndef fan_out(state):\n    '''Dispara los 3 analistas EN PARALELO'''\n    return [\n        Send('sentiment', state),\n        Send('entities', state),\n        Send('summary', state)\n    ]\n\ndef aggregate(state):\n    '''Combina todos los anÃ¡lisis'''\n    report = f'''REPORTE FINAL:\n    Sentimiento: {state.get(\"sentiment\", \"N/A\")}\n    Entidades: {state.get(\"entities\", [])}\n    Resumen: {state.get(\"summary\", \"N/A\")}\n    '''\n    return {'final_report': report}\n\nprint('âœ… Fan-out y aggregator definidos')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Construir grafo paralelo\n\ngraph = StateGraph(AnalysisState)\n\ngraph.add_node('sentiment', sentiment_analyst)\ngraph.add_node('entities', entity_analyst)\ngraph.add_node('summary', summary_analyst)\ngraph.add_node('aggregate', aggregate)\n\n# Fan-out desde START\ngraph.add_conditional_edges(START, fan_out)\n\n# Fan-in a aggregate\ngraph.add_edge('sentiment', 'aggregate')\ngraph.add_edge('entities', 'aggregate')\ngraph.add_edge('summary', 'aggregate')\ngraph.add_edge('aggregate', END)\n\napp = graph.compile()\nprint('âœ… Grafo paralelo compilado')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# ğŸ¬ DEMO: Performance paralelo\n\nimport time\n\ndoc = 'LangGraph de LangChain es excelente para construir agentes. Permite workflows complejos.'\n\nprint('='*60)\nprint('ğŸš€ EJECUCIÃ“N PARALELA')\nprint('='*60)\n\nstart = time.time()\nresult = app.invoke({'document': doc})\nelapsed = time.time() - start\n\nprint(f'\\nâ±ï¸ Tiempo: {elapsed:.2f}s')\nprint(f'\\n{result[\"final_report\"]}')\nprint('\\nğŸ’¡ Los 3 anÃ¡lisis se ejecutaron AL MISMO TIEMPO')"}
        ]
    },
    {
        "path": "modulo_2/04_instructor_ejercicio_2_3_orchestrator.ipynb",
        "title": "ğŸ¼ Ejercicio 2.3: Orchestrator-Workers",
        "module": "MÃ³dulo 2: Patrones Multi-Agente",
        "exercise": "2.3",
        "time": "10 minutos",
        "objectives": [
            "Implementar orchestrator que planifica",
            "Crear workers especializados",
            "Routing dinÃ¡mico basado en decisiones",
            "Permitir re-planificaciÃ³n"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"Ejercicio 2.3: Orchestrator-Workers.\n> El orchestrator es el 'cerebro' - decide quÃ© workers necesita.\n> Los workers son las 'manos' - ejecutan tareas especÃ­ficas.\""},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "from typing import TypedDict, List\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END\n\nclass OrchestratorState(TypedDict):\n    query: str\n    plan: str\n    worker_results: List[str]\n    final_answer: str\n\nllm = ChatOpenAI(model='gpt-4o-mini')\nprint('âœ… Setup')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Orchestrator - decide quÃ© hacer\n\ndef orchestrator(state):\n    '''Decide quÃ© worker necesitamos'''\n    query = state['query']\n    results = state.get('worker_results', [])\n    \n    # Â¿Ya tenemos suficiente info?\n    if len(results) >= 2:\n        return {'plan': 'synthesize'}\n    \n    # Decidir quÃ© worker usar\n    prompt = f'''Query: {query}\n    Results so far: {results}\n    \n    Â¿QuÃ© worker necesitamos?\n    - search_worker: buscar informaciÃ³n\n    - analyze_worker: analizar datos\n    - done: suficiente info\n    \n    Responde SOLO: search_worker, analyze_worker, o done'''\n    \n    decision = llm.invoke(prompt).content.strip().lower()\n    print(f'ğŸ¼ Orchestrator decide: {decision}')\n    return {'plan': decision}\n\nprint('âœ… Orchestrator definido')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Workers\n\ndef search_worker(state):\n    print('ğŸ” Search worker ejecutando...')\n    result = f'BÃºsqueda completada para: {state[\"query\"][:50]}'\n    return {'worker_results': [result]}\n\ndef analyze_worker(state):\n    print('ğŸ“Š Analyze worker ejecutando...')\n    result = f'AnÃ¡lisis completado de: {state[\"query\"][:50]}'\n    return {'worker_results': [result]}\n\ndef synthesize(state):\n    print('ğŸ”¨ Sintetizando resultados...')\n    answer = f'Respuesta basada en: {\", \".join(state[\"worker_results\"])}'\n    return {'final_answer': answer}\n\nprint('âœ… Workers definidos')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Routing dinÃ¡mico\n\ndef route_decision(state):\n    plan = state['plan']\n    if plan == 'search_worker':\n        return 'search'\n    elif plan == 'analyze_worker':\n        return 'analyze'\n    elif plan == 'synthesize' or plan == 'done':\n        return 'synthesize'\n    return 'end'\n\nprint('âœ… Router definido')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Construir grafo\n\ngraph = StateGraph(OrchestratorState)\n\ngraph.add_node('orchestrator', orchestrator)\ngraph.add_node('search', search_worker)\ngraph.add_node('analyze', analyze_worker)\ngraph.add_node('synthesize', synthesize)\n\n# Orchestrator decide\ngraph.add_edge(START, 'orchestrator')\ngraph.add_conditional_edges(\n    'orchestrator',\n    route_decision,\n    {\n        'search': 'search',\n        'analyze': 'analyze',\n        'synthesize': 'synthesize',\n        'end': END\n    }\n)\n\n# Workers vuelven al orchestrator\ngraph.add_edge('search', 'orchestrator')\ngraph.add_edge('analyze', 'orchestrator')\ngraph.add_edge('synthesize', END)\n\napp = graph.compile()\nprint('âœ… Sistema orchestrator-workers compilado')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# ğŸ¬ DEMO\n\nquery = 'Investiga tendencias de LangGraph en 2024'\n\nprint('='*60)\nprint('ğŸ¼ ORCHESTRATOR-WORKERS')\nprint('='*60)\nprint(f'Query: {query}\\n')\n\nresult = app.invoke({'query': query, 'worker_results': []})\n\nprint(f'\\nResultados de workers: {result[\"worker_results\"]}')\nprint(f'\\nRespuesta final: {result.get(\"final_answer\", \"En proceso\")}')"}
        ]
    },

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # MÃ“DULO 3: AGENTES AUTÃ“NOMOS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    {
        "path": "modulo_3/01_instructor_autonomia_overview.ipynb",
        "title": "ğŸ¤– Agentes AutÃ³nomos - Overview",
        "module": "MÃ³dulo 3: Agentes AutÃ³nomos",
        "exercise": "Overview",
        "time": "15 minutos",
        "objectives": [
            "Entender verdadera autonomÃ­a",
            "Plan-Execute-Evaluate pattern",
            "Handoffs dinÃ¡micos",
            "Memoria compartida"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"MÃ³dulo 3: Agentes verdaderamente autÃ³nomos.\n> No solo ejecutan - PLANIFICAN, SE COORDINAN, y APRENDEN.\""},
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ¯ Los 3 Conceptos\n\n### 1. PLAN-EXECUTE\n```\nPlanner â†’ Executor â†’ Evaluator â†’ Re-plan?\n```\n\n### 2. HANDOFFS\n```\nAgent A â†’ (decide transferir) â†’ Agent B\n```\n\n### 3. MEMORIA\n```\nAgent lee/escribe â†’ Memoria Compartida\n```"}
        ]
    },
    {
        "path": "modulo_3/02_instructor_ejercicio_3_1_plan_execute.ipynb",
        "title": "ğŸ“‹ Ejercicio 3.1: Plan-Execute-Evaluate",
        "module": "MÃ³dulo 3: Agentes AutÃ³nomos",
        "exercise": "3.1",
        "time": "17 minutos",
        "objectives": [
            "Implementar planner que crea plan completo",
            "Executor que ejecuta paso a paso",
            "Evaluator que verifica progreso",
            "Loop de ejecuciÃ³n con lÃ­mites"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"Plan-Execute: El agente PLANIFICA primero, EJECUTA despuÃ©s.\n> Como un chef que lee toda la receta antes de cocinar.\""},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "from typing import TypedDict, List\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END\n\nclass PlanExecuteState(TypedDict):\n    query: str\n    plan: List[str]\n    current_step: int\n    results: List[str]\n    evaluation: str\n\nllm = ChatOpenAI(model='gpt-4o-mini')\nprint('âœ… Setup')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Planner\n\ndef planner(state):\n    '''Crea plan completo'''\n    query = state['query']\n    \n    prompt = f'''Crea un plan de 3 pasos para: {query}\n    \n    Formato:\n    1. [paso 1]\n    2. [paso 2]\n    3. [paso 3]'''\n    \n    plan_text = llm.invoke(prompt).content\n    steps = [line.strip() for line in plan_text.split('\\n') if line.strip() and line[0].isdigit()]\n    \n    print(f'ğŸ“‹ Plan creado con {len(steps)} pasos')\n    for step in steps:\n        print(f'  {step}')\n    \n    return {'plan': steps, 'current_step': 0, 'results': []}\n\nprint('âœ… Planner definido')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Executor\n\ndef executor(state):\n    '''Ejecuta paso actual'''\n    plan = state['plan']\n    current = state['current_step']\n    \n    if current >= len(plan):\n        return state\n    \n    step = plan[current]\n    print(f'âš™ï¸ Ejecutando paso {current+1}: {step[:50]}...')\n    \n    # Simular ejecuciÃ³n\n    result = f'Resultado del paso {current+1}'\n    \n    return {\n        'results': state['results'] + [result],\n        'current_step': current + 1\n    }\n\nprint('âœ… Executor definido')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# DecisiÃ³n de continuar\n\ndef should_continue(state):\n    current = state['current_step']\n    total = len(state['plan'])\n    \n    # LÃ­mite de seguridad\n    if current > 10:\n        return 'end'\n    \n    if current >= total:\n        return 'evaluate'\n    return 'execute'\n\nprint('âœ… Router definido')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Evaluator\n\ndef evaluator(state):\n    '''EvalÃºa si el plan funcionÃ³'''\n    print('âœ… Evaluando resultados...')\n    eval = f'Plan completado. {len(state[\"results\"])} pasos ejecutados.'\n    return {'evaluation': eval}\n\nprint('âœ… Evaluator definido')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Construir grafo\n\ngraph = StateGraph(PlanExecuteState)\n\ngraph.add_node('planner', planner)\ngraph.add_node('executor', executor)\ngraph.add_node('evaluator', evaluator)\n\ngraph.add_edge(START, 'planner')\ngraph.add_edge('planner', 'executor')\ngraph.add_conditional_edges(\n    'executor',\n    should_continue,\n    {\n        'execute': 'executor',  # Loop\n        'evaluate': 'evaluator',\n        'end': END\n    }\n)\ngraph.add_edge('evaluator', END)\n\napp = graph.compile()\nprint('âœ… Plan-Execute compilado')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# ğŸ¬ DEMO\n\nquery = 'Investiga las tendencias de IA en 2024 y crea un reporte'\n\nprint('='*60)\nprint('ğŸ“‹ PLAN-EXECUTE-EVALUATE')\nprint('='*60)\nprint(f'Query: {query}\\n')\n\nresult = app.invoke({'query': query})\n\nprint(f'\\nPlan: {result[\"plan\"]}')\nprint(f'\\nResultados: {result[\"results\"]}')\nprint(f'\\nEvaluaciÃ³n: {result[\"evaluation\"]}')"}
        ]
    },
    {
        "path": "modulo_3/03_instructor_ejercicio_3_2_handoffs.ipynb",
        "title": "ğŸ¤ Ejercicio 3.2: Handoffs DinÃ¡micos",
        "module": "MÃ³dulo 3: Agentes AutÃ³nomos",
        "exercise": "3.2",
        "time": "12 minutos",
        "objectives": [
            "Crear tools de transferencia",
            "Agentes que deciden cuÃ¡ndo transferir",
            "Routing basado en tool_calls",
            "Ciclos de handoff"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"Handoffs: Los agentes se PASAN el control.\n> Como un hospital: recepciÃ³n â†’ especialista â†’ otro especialista.\""},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "from typing import Annotated\nfrom langchain_core.messages import HumanMessage\nfrom langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END\nimport operator\n\nclass HandoffState(TypedDict):\n    messages: Annotated[list, operator.add]\n    next_agent: str\n\nllm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\nprint('âœ… Setup')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Tools de transferencia\n\n@tool\ndef transfer_to_technical(reason: str) -> str:\n    '''Transfiere al agente tÃ©cnico. Usa cuando hay problemas tÃ©cnicos.'''\n    return f'TRANSFER:technical:{reason}'\n\n@tool\ndef transfer_to_billing(reason: str) -> str:\n    '''Transfiere al agente de billing. Usa para temas de facturaciÃ³n.'''\n    return f'TRANSFER:billing:{reason}'\n\nprint('âœ… Transfer tools definidas')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Agentes con handoff\n\nsupport_tools = [transfer_to_technical, transfer_to_billing]\nsupport_llm = llm.bind_tools(support_tools)\n\ndef support_agent(state):\n    print('ğŸ“ Support agent...')\n    response = support_llm.invoke(state['messages'])\n    \n    # Â¿DecidiÃ³ transferir?\n    if response.tool_calls:\n        call = response.tool_calls[0]\n        if 'transfer_to' in call['name']:\n            dest = call['name'].split('_')[-1]\n            print(f'  â†’ Transfiriendo a {dest}')\n            return {'messages': [response], 'next_agent': dest}\n    \n    return {'messages': [response], 'next_agent': 'end'}\n\ndef technical_agent(state):\n    print('ğŸ”§ Technical agent resolviendo...')\n    response = llm.invoke(state['messages'] + [HumanMessage('(Agente tÃ©cnico) Resuelvo el problema.')])\n    return {'messages': [response], 'next_agent': 'support'}\n\ndef billing_agent(state):\n    print('ğŸ’° Billing agent resolviendo...')\n    response = llm.invoke(state['messages'] + [HumanMessage('(Agente billing) Resuelvo el problema.')])\n    return {'messages': [response], 'next_agent': 'support'}\n\nprint('âœ… Agentes con handoff definidos')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Routing de handoffs\n\ndef route_handoff(state):\n    next_agent = state.get('next_agent', 'end')\n    if next_agent == 'technical':\n        return 'technical'\n    elif next_agent == 'billing':\n        return 'billing'\n    elif next_agent == 'support':\n        return 'support'\n    return 'end'\n\nprint('âœ… Router definido')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Construir grafo\n\ngraph = StateGraph(HandoffState)\n\ngraph.add_node('support', support_agent)\ngraph.add_node('technical', technical_agent)\ngraph.add_node('billing', billing_agent)\n\ngraph.add_edge(START, 'support')\ngraph.add_conditional_edges(\n    'support',\n    route_handoff,\n    {\n        'technical': 'technical',\n        'billing': 'billing',\n        'support': 'support',\n        'end': END\n    }\n)\ngraph.add_edge('technical', 'support')\ngraph.add_edge('billing', 'support')\n\napp = graph.compile()\nprint('âœ… Sistema de handoffs compilado')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# ğŸ¬ DEMO\n\nquery = 'Mi API da error 500 y mi factura estÃ¡ incorrecta'\n\nprint('='*60)\nprint('ğŸ¤ HANDOFFS DINÃMICOS')\nprint('='*60)\nprint(f'Query: {query}\\n')\n\nresult = app.invoke({'messages': [HumanMessage(query)], 'next_agent': ''})\n\nprint(f'\\nMensajes intercambiados: {len(result[\"messages\"])}')\nprint(f'Ãšltimo mensaje: {result[\"messages\"][-1].content[:100]}...')"}
        ]
    },
    {
        "path": "modulo_3/04_instructor_ejercicio_3_3_memoria.ipynb",
        "title": "ğŸ§  Ejercicio 3.3: Memoria Compartida",
        "module": "MÃ³dulo 3: Agentes AutÃ³nomos",
        "exercise": "3.3",
        "time": "10 minutos",
        "objectives": [
            "Usar operator.add para acumular",
            "Compartir hechos entre agentes",
            "Contexto persistente",
            "Multi-turno conversations"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"Memoria compartida: Los agentes RECUERDAN.\n> No empiezan de cero cada vez.\""},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "from typing import Annotated\nimport operator\nfrom langchain_core.messages import HumanMessage, SystemMessage\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END\n\nclass MemoryState(TypedDict):\n    messages: Annotated[list, operator.add]\n    facts: Annotated[list, operator.add]  # â† Acumula\n\nllm = ChatOpenAI(model='gpt-4o-mini')\nprint('âœ… Setup')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Agente con memoria\n\ndef agent_with_memory(state):\n    '''Agente que usa y actualiza memoria'''\n    messages = state['messages']\n    facts = state.get('facts', [])\n    \n    # Construir contexto con memoria\n    context = SystemMessage(content=f\"Hechos conocidos: {', '.join(facts)}\")\n    full_messages = [context] + messages\n    \n    print(f'ğŸ§  Memoria actual: {facts}')\n    \n    response = llm.invoke(full_messages)\n    \n    # Extraer nuevos hechos (simplificado)\n    new_facts = []\n    content_lower = response.content.lower()\n    if 'nombre' in content_lower and 'es' in content_lower:\n        # Extrae hechos simples\n        new_facts.append(f\"Nombre mencionado en conversaciÃ³n\")\n    \n    return {\n        'messages': [response],\n        'facts': new_facts  # Se AGREGAN a los existentes\n    }\n\nprint('âœ… Agente con memoria definido')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Construir grafo simple\n\ngraph = StateGraph(MemoryState)\ngraph.add_node('agent', agent_with_memory)\ngraph.add_edge(START, 'agent')\ngraph.add_edge('agent', END)\n\napp = graph.compile()\nprint('âœ… Sistema con memoria compilado')"},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# ğŸ¬ DEMO: ConversaciÃ³n multi-turno\n\nconversacion = [\n    'Me llamo Juan',\n    'Â¿CuÃ¡l es mi nombre?',\n    'Vivo en MÃ©xico',\n    'Â¿DÃ³nde vivo?'\n]\n\nstate = {'messages': [], 'facts': []}\n\nprint('='*60)\nprint('ğŸ§  MEMORIA COMPARTIDA')\nprint('='*60)\n\nfor turno in conversacion:\n    print(f'\\nUsuario: {turno}')\n    state['messages'] = [HumanMessage(turno)]\n    result = app.invoke(state)\n    \n    # Actualizar state con resultados acumulados\n    state['facts'] = result['facts']\n    \n    print(f'Agente: {result[\"messages\"][-1].content}')\n    print(f'Memoria: {result[\"facts\"]}')"}
        ]
    },

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # MÃ“DULO 4: APLICACIONES DE NEGOCIO
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    {
        "path": "modulo_4/01_instructor_produccion_overview.ipynb",
        "title": "ğŸ­ ProducciÃ³n - Consideraciones Clave",
        "module": "MÃ³dulo 4: Aplicaciones de Negocio",
        "exercise": "Overview",
        "time": "15 minutos",
        "objectives": [
            "Checklist de producciÃ³n",
            "Retry logic y error handling",
            "Logging y mÃ©tricas",
            "Costos y optimizaciÃ³n"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"MÃ³dulo 4: De prototipo a PRODUCCIÃ“N.\n> Todo lo que necesitas para sistemas REALES.\""},
            {"cell_type": "markdown", "metadata": {}, "source": "## âœ… Checklist de ProducciÃ³n\n\n### 1. Funcionalidad\n- Tests >80%\n- Error handling\n- ValidaciÃ³n de inputs\n\n### 2. Performance\n- Latencia < requisitos\n- Timeouts configurados\n- Retry logic\n\n### 3. Observabilidad\n- Logging estructurado\n- MÃ©tricas (latencia, costos)\n- LangSmith tracing\n\n### 4. Costos\n- Presupuesto definido\n- Monitoring por llamada\n- Modelos optimizados"}
        ]
    },
    {
        "path": "modulo_4/02_instructor_ejercicio_4_1_customer_support.ipynb",
        "title": "ğŸ§ Ejercicio 4.1: Customer Support Completo",
        "module": "MÃ³dulo 4: Aplicaciones de Negocio",
        "exercise": "4.1",
        "time": "20 minutos",
        "objectives": [
            "Sistema completo de customer support",
            "Confidence scoring",
            "EscalaciÃ³n a humano",
            "Logging y mÃ©tricas"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"Sistema REAL de customer support.\n> Con confidence, escalaciÃ³n, y logging completo.\""},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Ver ejercicio completo\n!cat ../../ejercicios/modulo_4/ejercicio_4_1_atencion_cliente/README.md | head -50"}
        ]
    },
    {
        "path": "modulo_4/03_instructor_ejercicio_4_2_document_analysis.ipynb",
        "title": "ğŸ“„ Ejercicio 4.2: AnÃ¡lisis de Documentos",
        "module": "MÃ³dulo 4: Aplicaciones de Negocio",
        "exercise": "4.2",
        "time": "20 minutos",
        "objectives": [
            "Pipeline multi-etapa",
            "AnÃ¡lisis paralelo",
            "AgregaciÃ³n de resultados",
            "ValidaciÃ³n de calidad"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"Pipeline de anÃ¡lisis de documentos.\n> Preproceso â†’ AnÃ¡lisis paralelo â†’ AgregaciÃ³n â†’ ValidaciÃ³n.\""},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Ver ejercicio\n!cat ../../ejercicios/modulo_4/ejercicio_4_2_analisis_datos/README.md | head -50"}
        ]
    },
    {
        "path": "modulo_4/04_instructor_ejercicio_4_3_research.ipynb",
        "title": "ğŸ”¬ Ejercicio 4.3: Asistente de InvestigaciÃ³n",
        "module": "MÃ³dulo 4: Aplicaciones de Negocio",
        "exercise": "4.3",
        "time": "15 minutos",
        "objectives": [
            "Sistema de investigaciÃ³n completo",
            "Plan-Execute aplicado",
            "BÃºsquedas paralelas",
            "SÃ­ntesis de informaciÃ³n"
        ],
        "cells": [
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¬ SCRIPT\n\n> \"Asistente de investigaciÃ³n empresarial.\n> Combina TODOS los patterns que vimos.\""},
            {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": "# Ver ejercicio\n!cat ../../ejercicios/modulo_4/ejercicio_4_3_investigacion/README.md | head -50"},
            {"cell_type": "markdown", "metadata": {}, "source": "## ğŸ’¡ TIP\n\n> \"Este ejercicio es complejo - Ãºsenlo como referencia.\n> Combina Plan-Execute + Parallelization + Memoria.\n> Es un buen ejemplo de sistema REAL.\""}
        ]
    }
]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CREAR TODOS LOS NOTEBOOKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("ğŸš€ Generando notebooks de mÃ³dulos 2, 3 y 4...\n")

for nb_config in notebooks_to_create:
    notebook = create_notebook_template(
        title=nb_config["title"],
        module=nb_config["module"],
        exercise_num=nb_config["exercise"],
        time=nb_config["time"],
        objectives=nb_config["objectives"],
        cells_content=nb_config["cells"]
    )

    filepath = os.path.join(".", nb_config["path"])
    os.makedirs(os.path.dirname(filepath), exist_ok=True)

    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(notebook, f, indent=1, ensure_ascii=False)

    print(f"âœ… {nb_config['path']}")

print(f"\nğŸ‰ Â¡Completado! Se crearon {len(notebooks_to_create)} notebooks.")
print("\nEstructura completa:")
print("  ğŸ“ modulo_2: 4 notebooks")
print("  ğŸ“ modulo_3: 4 notebooks")
print("  ğŸ“ modulo_4: 4 notebooks")
print("\nTotal: 12 notebooks nuevos + 3 existentes = 15 notebooks completos âœ¨")
