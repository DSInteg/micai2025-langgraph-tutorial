{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤ Ejercicio 3.2: Handoffs DinÃ¡micos\n\n",
    "**MÃ³dulo 3: Agentes AutÃ³nomos**  \n",
    "**Tiempo estimado**: 12 minutos  \n",
    "**Ejercicio**: 3.2\n\n",
    "---\n\n",
    "## ðŸŽ¯ Objetivos de Aprendizaje\n\n",
    "1. âœ… Crear tools de transferencia\n",
    "2. âœ… Agentes que deciden cuÃ¡ndo transferir\n",
    "3. âœ… Routing basado en tool_calls\n",
    "4. âœ… Ciclos de handoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ðŸ“‹ SETUP Y VERIFICACIÃ“N                                  â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n",
    "%pip install -q langgraph langchain-openai python-dotenv\n\n",
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "load_dotenv()\n\n",
    "print('='*50)\n",
    "print('   SETUP VERIFICATION')\n",
    "print('='*50)\n",
    "print(f\"âœ… Python {sys.version.split()[0]}\")\n",
    "print(f\"{'âœ…' if os.getenv('OPENAI_API_KEY') else 'âŒ'} OpenAI API Key\")\n",
    "print(f\"\\nðŸŽ¬ Ready!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ðŸ’¬ SCRIPT\n\n> \"Handoffs: Los agentes se PASAN el control.\n> Como un hospital: recepciÃ³n â†’ especialista â†’ otro especialista.\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from typing import Annotated\nfrom langchain_core.messages import HumanMessage\nfrom langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END\nimport operator\n\nclass HandoffState(TypedDict):\n    messages: Annotated[list, operator.add]\n    next_agent: str\n\nllm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\nprint('âœ… Setup')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Tools de transferencia\n\n@tool\ndef transfer_to_technical(reason: str) -> str:\n    '''Transfiere al agente tÃ©cnico. Usa cuando hay problemas tÃ©cnicos.'''\n    return f'TRANSFER:technical:{reason}'\n\n@tool\ndef transfer_to_billing(reason: str) -> str:\n    '''Transfiere al agente de billing. Usa para temas de facturaciÃ³n.'''\n    return f'TRANSFER:billing:{reason}'\n\nprint('âœ… Transfer tools definidas')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Agentes con handoff\n\nsupport_tools = [transfer_to_technical, transfer_to_billing]\nsupport_llm = llm.bind_tools(support_tools)\n\ndef support_agent(state):\n    print('ðŸ“ž Support agent...')\n    response = support_llm.invoke(state['messages'])\n    \n    # Â¿DecidiÃ³ transferir?\n    if response.tool_calls:\n        call = response.tool_calls[0]\n        if 'transfer_to' in call['name']:\n            dest = call['name'].split('_')[-1]\n            print(f'  â†’ Transfiriendo a {dest}')\n            return {'messages': [response], 'next_agent': dest}\n    \n    return {'messages': [response], 'next_agent': 'end'}\n\ndef technical_agent(state):\n    print('ðŸ”§ Technical agent resolviendo...')\n    response = llm.invoke(state['messages'] + [HumanMessage('(Agente tÃ©cnico) Resuelvo el problema.')])\n    return {'messages': [response], 'next_agent': 'support'}\n\ndef billing_agent(state):\n    print('ðŸ’° Billing agent resolviendo...')\n    response = llm.invoke(state['messages'] + [HumanMessage('(Agente billing) Resuelvo el problema.')])\n    return {'messages': [response], 'next_agent': 'support'}\n\nprint('âœ… Agentes con handoff definidos')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Routing de handoffs\n\ndef route_handoff(state):\n    next_agent = state.get('next_agent', 'end')\n    if next_agent == 'technical':\n        return 'technical'\n    elif next_agent == 'billing':\n        return 'billing'\n    elif next_agent == 'support':\n        return 'support'\n    return 'end'\n\nprint('âœ… Router definido')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Construir grafo\n\ngraph = StateGraph(HandoffState)\n\ngraph.add_node('support', support_agent)\ngraph.add_node('technical', technical_agent)\ngraph.add_node('billing', billing_agent)\n\ngraph.add_edge(START, 'support')\ngraph.add_conditional_edges(\n    'support',\n    route_handoff,\n    {\n        'technical': 'technical',\n        'billing': 'billing',\n        'support': 'support',\n        'end': END\n    }\n)\ngraph.add_edge('technical', 'support')\ngraph.add_edge('billing', 'support')\n\napp = graph.compile()\nprint('âœ… Sistema de handoffs compilado')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ðŸŽ¬ DEMO\n\nquery = 'Mi API da error 500 y mi factura estÃ¡ incorrecta'\n\nprint('='*60)\nprint('ðŸ¤ HANDOFFS DINÃMICOS')\nprint('='*60)\nprint(f'Query: {query}\\n')\n\nresult = app.invoke({'messages': [HumanMessage(query)], 'next_agent': ''})\n\nprint(f'\\nMensajes intercambiados: {len(result[\"messages\"])}')\nprint(f'Ãšltimo mensaje: {result[\"messages\"][-1].content[:100]}...')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n",
    "## âœ… CHECKPOINT FINAL\n\n",
    "- [ ] CÃ³digo ejecuta sin errores\n",
    "- [ ] Conceptos clave entendidos\n",
    "- [ ] Listos para continuar\n\n",
    "### ðŸ’¬ PREGUNTA:\n",
    "> \"Â¿Alguna duda antes de continuar?\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}