{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“‹ Ejercicio 3.1: Plan-Execute-Evaluate\n",
    "\n",
    "**MÃ³dulo 3: Agentes AutÃ³nomos**  \n",
    "**Tiempo estimado**: 17 minutos  \n",
    "**Ejercicio**: 3.1\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Objetivos de Aprendizaje\n",
    "\n",
    "1. âœ… Implementar planner que crea plan completo\n",
    "2. âœ… Executor que ejecuta paso a paso\n",
    "3. âœ… Evaluator que verifica progreso\n",
    "4. âœ… Loop de ejecuciÃ³n con lÃ­mites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ðŸ“‹ SETUP Y VERIFICACIÃ“N                                  â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "%pip install -q langgraph langchain-openai python-dotenv\n",
    "\n",
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "load_dotenv()\n",
    "\n",
    "print('='*50)\n",
    "print('   SETUP VERIFICATION')\n",
    "print('='*50)\n",
    "print(f\"âœ… Python {sys.version.split()[0]}\")\n",
    "print(f\"{'âœ…' if os.getenv('OPENAI_API_KEY') else 'âŒ'} OpenAI API Key\")\n",
    "print(f\"\\nðŸŽ¬ Ready!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¬ SCRIPT\n",
    "\n",
    "> \"Plan-Execute: El agente PLANIFICA primero, EJECUTA despuÃ©s.\n",
    "> Como un chef que lee toda la receta antes de cocinar.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class PlanExecuteState(TypedDict):\n",
    "    query: str\n",
    "    plan: List[str]\n",
    "    current_step: int\n",
    "    results: List[str]\n",
    "    evaluation: str\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "print('âœ… Setup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planner\n",
    "\n",
    "def planner(state):\n",
    "    '''Crea plan completo'''\n",
    "    query = state['query']\n",
    "    \n",
    "    prompt = f'''Crea un plan de 3 pasos para: {query}\n",
    "    \n",
    "    Formato:\n",
    "    1. [paso 1]\n",
    "    2. [paso 2]\n",
    "    3. [paso 3]'''\n",
    "    \n",
    "    plan_text = llm.invoke(prompt).content\n",
    "    steps = [line.strip() for line in plan_text.split('\\n') if line.strip() and line[0].isdigit()]\n",
    "    \n",
    "    print(f'ðŸ“‹ Plan creado con {len(steps)} pasos')\n",
    "    for step in steps:\n",
    "        print(f'  {step}')\n",
    "    \n",
    "    return {'plan': steps, 'current_step': 0, 'results': []}\n",
    "\n",
    "print('âœ… Planner definido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executor\n",
    "\n",
    "def executor(state):\n",
    "    '''Ejecuta paso actual'''\n",
    "    plan = state['plan']\n",
    "    current = state['current_step']\n",
    "    \n",
    "    if current >= len(plan):\n",
    "        return state\n",
    "    \n",
    "    step = plan[current]\n",
    "    print(f'âš™ï¸ Ejecutando paso {current+1}: {step[:50]}...')\n",
    "    \n",
    "    # Simular ejecuciÃ³n\n",
    "    result = f'Resultado del paso {current+1}'\n",
    "    \n",
    "    return {\n",
    "        'results': state['results'] + [result],\n",
    "        'current_step': current + 1\n",
    "    }\n",
    "\n",
    "print('âœ… Executor definido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisiÃ³n de continuar\n",
    "\n",
    "def should_continue(state):\n",
    "    current = state['current_step']\n",
    "    total = len(state['plan'])\n",
    "    \n",
    "    # LÃ­mite de seguridad\n",
    "    if current > 10:\n",
    "        return 'end'\n",
    "    \n",
    "    if current >= total:\n",
    "        return 'evaluate'\n",
    "    return 'execute'\n",
    "\n",
    "print('âœ… Router definido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "\n",
    "def evaluator(state):\n",
    "    '''EvalÃºa si el plan funcionÃ³'''\n",
    "    print('âœ… Evaluando resultados...')\n",
    "    eval = f'Plan completado. {len(state[\"results\"])} pasos ejecutados.'\n",
    "    return {'evaluation': eval}\n",
    "\n",
    "print('âœ… Evaluator definido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir grafo\n",
    "\n",
    "graph = StateGraph(PlanExecuteState)\n",
    "\n",
    "graph.add_node('planner', planner)\n",
    "graph.add_node('executor', executor)\n",
    "graph.add_node('evaluator', evaluator)\n",
    "\n",
    "graph.add_edge(START, 'planner')\n",
    "graph.add_edge('planner', 'executor')\n",
    "graph.add_conditional_edges(\n",
    "    'executor',\n",
    "    should_continue,\n",
    "    {\n",
    "        'execute': 'executor',  # Loop\n",
    "        'evaluate': 'evaluator',\n",
    "        'end': END\n",
    "    }\n",
    ")\n",
    "graph.add_edge('evaluator', END)\n",
    "\n",
    "app = graph.compile()\n",
    "print('âœ… Plan-Execute compilado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "# View\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¬ DEMO\n",
    "\n",
    "query = 'Investiga las tendencias de IA en 2024 y crea un reporte'\n",
    "\n",
    "print('='*60)\n",
    "print('ðŸ“‹ PLAN-EXECUTE-EVALUATE')\n",
    "print('='*60)\n",
    "print(f'Query: {query}\\n')\n",
    "\n",
    "result = app.invoke({'query': query})\n",
    "\n",
    "print(f'\\nPlan: {result[\"plan\"]}')\n",
    "print(f'\\nResultados: {result[\"results\"]}')\n",
    "print(f'\\nEvaluaciÃ³n: {result[\"evaluation\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… CHECKPOINT FINAL\n",
    "\n",
    "- [ ] CÃ³digo ejecuta sin errores\n",
    "- [ ] Conceptos clave entendidos\n",
    "- [ ] Listos para continuar\n",
    "\n",
    "### ðŸ’¬ PREGUNTA:\n",
    "> \"Â¿Alguna duda antes de continuar?\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
