{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Ejercicio 3.3: Memoria Compartida\n\n",
    "**MÃ³dulo 3: Agentes AutÃ³nomos**  \n",
    "**Tiempo estimado**: 10 minutos  \n",
    "**Ejercicio**: 3.3\n\n",
    "---\n\n",
    "## ðŸŽ¯ Objetivos de Aprendizaje\n\n",
    "1. âœ… Usar operator.add para acumular\n",
    "2. âœ… Compartir hechos entre agentes\n",
    "3. âœ… Contexto persistente\n",
    "4. âœ… Multi-turno conversations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ðŸ“‹ SETUP Y VERIFICACIÃ“N                                  â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n",
    "%pip install -q langgraph langchain-openai python-dotenv\n\n",
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "load_dotenv()\n\n",
    "print('='*50)\n",
    "print('   SETUP VERIFICATION')\n",
    "print('='*50)\n",
    "print(f\"âœ… Python {sys.version.split()[0]}\")\n",
    "print(f\"{'âœ…' if os.getenv('OPENAI_API_KEY') else 'âŒ'} OpenAI API Key\")\n",
    "print(f\"\\nðŸŽ¬ Ready!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ðŸ’¬ SCRIPT\n\n> \"Memoria compartida: Los agentes RECUERDAN.\n> No empiezan de cero cada vez.\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from typing import Annotated\nimport operator\nfrom langchain_core.messages import HumanMessage, SystemMessage\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END\n\nclass MemoryState(TypedDict):\n    messages: Annotated[list, operator.add]\n    facts: Annotated[list, operator.add]  # â† Acumula\n\nllm = ChatOpenAI(model='gpt-4o-mini')\nprint('âœ… Setup')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Agente con memoria\n\ndef agent_with_memory(state):\n    '''Agente que usa y actualiza memoria'''\n    messages = state['messages']\n    facts = state.get('facts', [])\n    \n    # Construir contexto con memoria\n    context = SystemMessage(content=f\"Hechos conocidos: {', '.join(facts)}\")\n    full_messages = [context] + messages\n    \n    print(f'ðŸ§  Memoria actual: {facts}')\n    \n    response = llm.invoke(full_messages)\n    \n    # Extraer nuevos hechos (simplificado)\n    new_facts = []\n    content_lower = response.content.lower()\n    if 'nombre' in content_lower and 'es' in content_lower:\n        # Extrae hechos simples\n        new_facts.append(f\"Nombre mencionado en conversaciÃ³n\")\n    \n    return {\n        'messages': [response],\n        'facts': new_facts  # Se AGREGAN a los existentes\n    }\n\nprint('âœ… Agente con memoria definido')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Construir grafo simple\n\ngraph = StateGraph(MemoryState)\ngraph.add_node('agent', agent_with_memory)\ngraph.add_edge(START, 'agent')\ngraph.add_edge('agent', END)\n\napp = graph.compile()\nprint('âœ… Sistema con memoria compilado')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ðŸŽ¬ DEMO: ConversaciÃ³n multi-turno\n\nconversacion = [\n    'Me llamo Juan',\n    'Â¿CuÃ¡l es mi nombre?',\n    'Vivo en MÃ©xico',\n    'Â¿DÃ³nde vivo?'\n]\n\nstate = {'messages': [], 'facts': []}\n\nprint('='*60)\nprint('ðŸ§  MEMORIA COMPARTIDA')\nprint('='*60)\n\nfor turno in conversacion:\n    print(f'\\nUsuario: {turno}')\n    state['messages'] = [HumanMessage(turno)]\n    result = app.invoke(state)\n    \n    # Actualizar state con resultados acumulados\n    state['facts'] = result['facts']\n    \n    print(f'Agente: {result[\"messages\"][-1].content}')\n    print(f'Memoria: {result[\"facts\"]}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n",
    "## âœ… CHECKPOINT FINAL\n\n",
    "- [ ] CÃ³digo ejecuta sin errores\n",
    "- [ ] Conceptos clave entendidos\n",
    "- [ ] Listos para continuar\n\n",
    "### ðŸ’¬ PREGUNTA:\n",
    "> \"Â¿Alguna duda antes de continuar?\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}