"""
Ejercicio 1.1: Workflow Simple con Prompt Chaining - SOLUCI√ìN COMPLETA

Este m√≥dulo implementa un pipeline determin√≠stico de procesamiento de texto
que extrae ideas clave, resume y traduce art√≠culos.

Conceptos implementados:
- StateGraph: Grafo de estados para workflows
- TypedDict: Definici√≥n de estructura de estado
- Nodos: Funciones que transforman el estado
- Edges: Conexiones entre nodos
- Prompt engineering: Construcci√≥n de prompts efectivos
"""

from typing import TypedDict
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END

# Cargar variables de entorno (API keys)
load_dotenv()

# =============================================================================
# DEFINICI√ìN DEL ESTADO
# =============================================================================

class WorkflowState(TypedDict):
    """
    Estado compartido entre todos los nodos del workflow.

    Este diccionario fluye a trav√©s del grafo y cada nodo puede:
    - Leer cualquier campo
    - Actualizar campos retornando un diccionario parcial

    Importante: LangGraph autom√°ticamente fusiona (merge) el diccionario
    retornado con el estado existente, por lo que solo necesitas retornar
    los campos que quieres actualizar.

    Campos:
        article: Art√≠culo original en espa√±ol (input del usuario)
        key_points: Puntos clave extra√≠dos del art√≠culo
        summary: Resumen del art√≠culo basado en los puntos clave
        translation: Traducci√≥n del resumen al ingl√©s
    """
    article: str
    key_points: str
    summary: str
    translation: str


# =============================================================================
# CONFIGURACI√ìN DEL LLM
# =============================================================================

# Inicializar el modelo de lenguaje
# Usamos GPT-4o-mini por su balance entre costo y calidad
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.7,  # Creatividad moderada para textos m√°s naturales
)


# =============================================================================
# DEFINICI√ìN DE NODOS
# =============================================================================

def extract_key_points(state: WorkflowState) -> dict:
    """
    Nodo 1: Extrae las ideas principales del art√≠culo.

    Este nodo demuestra:
    - C√≥mo acceder al estado con state["campo"]
    - C√≥mo construir un prompt claro y espec√≠fico
    - C√≥mo invocar el LLM usando HumanMessage
    - C√≥mo retornar solo los campos actualizados

    Args:
        state: Estado actual del workflow con el art√≠culo original

    Returns:
        Diccionario con la clave 'key_points' actualizada
    """
    print("\n" + "="*70)
    print("üîç PASO 1: Extrayendo puntos clave del art√≠culo...")
    print("="*70)

    # 1. Acceder al art√≠culo del estado
    article = state["article"]

    # 2. Construir un prompt claro y espec√≠fico
    # Nota: Un buen prompt debe ser:
    # - Claro sobre la tarea
    # - Espec√≠fico sobre el formato deseado
    # - Conciso pero completo
    prompt = f"""Analiza el siguiente art√≠culo y extrae las 3-5 ideas principales.

Art√≠culo:
{article}

Por favor, responde solo con una lista numerada de los puntos clave m√°s importantes.
Cada punto debe ser conciso pero completo."""

    # 3. Invocar el LLM
    # HumanMessage representa un mensaje del usuario
    message = HumanMessage(content=prompt)

    # invoke() env√≠a el mensaje al LLM y espera la respuesta
    # Pasamos una lista de mensajes (aunque solo tengamos uno)
    response = llm.invoke([message])

    # 4. Extraer el contenido de la respuesta
    key_points = response.content

    # Mostrar resultado para seguimiento
    print(f"\nüìå Puntos clave extra√≠dos:\n{key_points}\n")

    # 5. Retornar solo el campo que actualizamos
    # LangGraph autom√°ticamente fusionar√° esto con el estado existente
    return {"key_points": key_points}


def summarize_content(state: WorkflowState) -> dict:
    """
    Nodo 2: Crea un resumen estructurado basado en los puntos clave.

    Este nodo demuestra:
    - C√≥mo un nodo puede depender de la salida del nodo anterior
    - C√≥mo pedir al LLM que genere texto con estructura espec√≠fica
    - La importancia de prompts que gu√≠en el estilo del output

    Args:
        state: Estado actual con key_points ya extra√≠dos

    Returns:
        Diccionario con la clave 'summary' actualizada
    """
    print("\n" + "="*70)
    print("üìù PASO 2: Creando resumen del contenido...")
    print("="*70)

    # 1. Obtener los puntos clave del estado
    # Nota: Este nodo NO necesita el art√≠culo original,
    # solo los puntos clave generados por el nodo anterior
    key_points = state["key_points"]

    # 2. Construir prompt para generar resumen coherente
    # Especificamos:
    # - La tarea (crear resumen)
    # - El formato deseado (3 p√°rrafos)
    # - El estilo (coherente y fluido)
    prompt = f"""Bas√°ndote en los siguientes puntos clave, escribe un resumen
coherente y fluido de aproximadamente 3 p√°rrafos.

El resumen debe:
- Ser natural y f√°cil de leer
- Conectar las ideas de manera l√≥gica
- Mantener la informaci√≥n importante

Puntos clave:
{key_points}

Resumen:"""

    # 3. Invocar el LLM
    message = HumanMessage(content=prompt)
    response = llm.invoke([message])
    summary = response.content

    # Mostrar resultado
    print(f"\nüìÑ Resumen generado:\n{summary}\n")

    # 4. Retornar campo actualizado
    return {"summary": summary}


def translate_summary(state: WorkflowState) -> dict:
    """
    Nodo 3: Traduce el resumen al ingl√©s.

    Este nodo demuestra:
    - Tareas de transformaci√≥n de lenguaje
    - C√≥mo pedir traducciones naturales (no literales)
    - El √∫ltimo paso en un pipeline secuencial

    Args:
        state: Estado actual con summary ya generado

    Returns:
        Diccionario con la clave 'translation' actualizada
    """
    print("\n" + "="*70)
    print("üåê PASO 3: Traduciendo resumen al ingl√©s...")
    print("="*70)

    # 1. Obtener el resumen del estado
    summary = state["summary"]

    # 2. Construir prompt para traducci√≥n natural
    # Importante: Pedimos traducci√≥n "natural y fluida"
    # para evitar traducciones demasiado literales
    prompt = f"""Traduce el siguiente texto al ingl√©s de manera natural y fluida.
Mant√©n el tono profesional pero accesible.

Texto en espa√±ol:
{summary}

Traducci√≥n al ingl√©s:"""

    # 3. Invocar el LLM
    message = HumanMessage(content=prompt)
    response = llm.invoke([message])
    translation = response.content

    # Mostrar resultado
    print(f"\nüåç Traducci√≥n completada:\n{translation}\n")

    # 4. Retornar campo actualizado
    return {"translation": translation}


# =============================================================================
# CONSTRUCCI√ìN DEL GRAFO
# =============================================================================

def build_graph() -> StateGraph:
    """
    Construye el grafo del workflow conectando los nodos.

    Este grafo representa un workflow DETERMIN√çSTICO:
    - Siempre ejecuta los mismos nodos en el mismo orden
    - No hay decisiones condicionales
    - Ideal para pipelines predecibles

    El flujo es:
    START ‚Üí extract_key_points ‚Üí summarize_content ‚Üí translate_summary ‚Üí END

    Returns:
        Grafo compilado listo para ejecutar
    """
    # 1. Crear el grafo especificando el tipo de estado
    # Esto permite a LangGraph validar y proporcionar type hints
    workflow = StateGraph(WorkflowState)

    # 2. Agregar los nodos al grafo
    # Sintaxis: add_node(nombre_string, funci√≥n_a_ejecutar)
    # El nombre es c√≥mo referenciamos el nodo en los edges
    workflow.add_node("extract", extract_key_points)
    workflow.add_node("summarize", summarize_content)
    workflow.add_node("translate", translate_summary)

    # 3. Definir el punto de entrada
    # Este es el primer nodo que se ejecutar√°
    workflow.set_entry_point("extract")

    # 4. Conectar los nodos con edges (conexiones)
    # add_edge(origen, destino) significa: "despu√©s de origen, ejecutar destino"
    workflow.add_edge("extract", "summarize")
    workflow.add_edge("summarize", "translate")

    # 5. Conectar el √∫ltimo nodo con END
    # END es una constante especial que marca el final del workflow
    workflow.add_edge("translate", END)

    # 6. Compilar el grafo
    # compile() valida el grafo y lo prepara para ejecuci√≥n
    # Retorna un objeto ejecutable
    return workflow.compile()


# =============================================================================
# EJECUCI√ìN DEL WORKFLOW
# =============================================================================

def main():
    """
    Funci√≥n principal que ejecuta el workflow completo.

    Flujo de ejecuci√≥n:
    1. Definir el art√≠culo de entrada
    2. Construir el grafo
    3. Crear el estado inicial
    4. Ejecutar el workflow con invoke()
    5. Mostrar resultados
    """
    print("\n" + "="*70)
    print("üöÄ INICIANDO WORKFLOW DE PROCESAMIENTO DE ART√çCULOS")
    print("="*70)

    # Art√≠culo de ejemplo sobre inteligencia artificial
    article = """
    La inteligencia artificial est√° transformando radicalmente la forma en que
    trabajamos y vivimos. Los sistemas de IA modernos pueden procesar grandes
    cantidades de informaci√≥n en segundos, identificar patrones complejos y
    hacer predicciones con una precisi√≥n sorprendente.

    En el √°mbito empresarial, las compa√±√≠as est√°n implementando agentes
    aut√≥nomos para automatizar tareas repetitivas, mejorar la atenci√≥n al
    cliente y optimizar procesos de negocio. Estos sistemas multi-agente pueden
    colaborar entre s√≠ para resolver problemas complejos que antes requer√≠an
    intervenci√≥n humana constante.

    Sin embargo, con estos avances vienen importantes desaf√≠os √©ticos y
    t√©cnicos. Es crucial desarrollar sistemas de IA que sean transparentes,
    explicables y alineados con valores humanos. La comunidad cient√≠fica est√°
    trabajando activamente en frameworks y mejores pr√°cticas para el desarrollo
    responsable de IA.
    """

    # Construir el grafo
    # Esta funci√≥n retorna un grafo compilado listo para ejecutar
    app = build_graph()

    # Crear el estado inicial
    # Debemos proporcionar todos los campos definidos en WorkflowState
    # Los campos vac√≠os ser√°n llenados por los nodos durante la ejecuci√≥n
    initial_state = {
        "article": article.strip(),
        "key_points": "",
        "summary": "",
        "translation": ""
    }

    # Ejecutar el workflow
    # invoke() es el m√©todo principal para ejecutar un grafo
    # - Toma el estado inicial
    # - Ejecuta cada nodo en orden
    # - Retorna el estado final con todos los campos actualizados
    print("\n‚öôÔ∏è  Ejecutando workflow...\n")
    final_state = app.invoke(initial_state)

    # Mostrar resultados finales
    print("\n" + "="*70)
    print("‚úÖ WORKFLOW COMPLETADO - RESULTADOS FINALES")
    print("="*70)

    print("\nüìå PUNTOS CLAVE:")
    print("-" * 70)
    print(final_state["key_points"])

    print("\nüìÑ RESUMEN (ESPA√ëOL):")
    print("-" * 70)
    print(final_state["summary"])

    print("\nüåç TRADUCCI√ìN (INGL√âS):")
    print("-" * 70)
    print(final_state["translation"])

    print("\n" + "="*70)
    print("üéâ ¬°Ejercicio completado exitosamente!")
    print("="*70)

    # Nota sobre el estado final:
    # final_state contiene TODOS los campos del estado:
    # - article: El art√≠culo original (sin cambios)
    # - key_points: Generado por extract_key_points()
    # - summary: Generado por summarize_content()
    # - translation: Generado por translate_summary()


if __name__ == "__main__":
    main()
