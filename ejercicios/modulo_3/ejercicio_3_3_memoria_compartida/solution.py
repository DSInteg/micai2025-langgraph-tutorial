"""
Ejercicio 3.3: Memoria Compartida entre Agentes - SOLUCIÃ“N COMPLETA

Implementa un sistema con memoria compartida persistente.
"""

from typing import TypedDict, List, Dict
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
import datetime

load_dotenv()

# =============================================================================
# ESTADO CON MEMORIA
# =============================================================================

class MemoryState(TypedDict):
    """
    Estado que incluye acceso a memoria compartida.

    La clave de este ejercicio es que 'memory' se comparte
    entre mÃºltiples invocaciones del grafo, permitiendo
    aprendizaje acumulativo.
    """
    query: str                   # Consulta actual del usuario
    user_id: str                # ID del usuario
    similar_cases: List[Dict]   # Casos similares encontrados
    solution: str               # SoluciÃ³n generada
    should_save: bool           # Si guardar en memoria
    memory: Dict                # Memoria compartida (persistente)


llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)


# =============================================================================
# FUNCIONES DE GESTIÃ“N DE MEMORIA
# =============================================================================

def search_similar_cases(query: str, memory: Dict, top_k: int = 3) -> List[Dict]:
    """
    Busca casos similares en la memoria usando bÃºsqueda por keywords.

    Algoritmo simple:
    1. Tokenizar query en palabras
    2. Para cada caso, calcular overlap de palabras
    3. Ordenar por overlap (relevancia)
    4. Retornar top-k

    En producciÃ³n, usarÃ­as:
    - Embeddings (OpenAI, Sentence Transformers)
    - Vector databases (Pinecone, Weaviate, ChromaDB)
    - BÃºsqueda semÃ¡ntica con cosine similarity

    Args:
        query: Consulta a buscar
        memory: Diccionario con casos previos
        top_k: NÃºmero de casos mÃ¡s relevantes

    Returns:
        Lista de hasta top_k casos mÃ¡s similares
    """
    if "cases" not in memory or not memory["cases"]:
        return []

    query_lower = query.lower()
    query_words = set(query_lower.split())

    # Calcular relevancia para cada caso
    scored_cases = []
    for case in memory["cases"]:
        case_query = case["query"].lower()
        case_words = set(case_query.split())

        # IntersecciÃ³n de palabras (Jaccard similarity simplificado)
        overlap = len(query_words & case_words)

        if overlap > 0:
            # Score mÃ¡s alto para casos con mÃ¡s overlap
            # TambiÃ©n considerar tags si existen
            tag_bonus = 0
            if "tags" in case:
                case_tags = set(case["tags"])
                # Verificar si algÃºn tag aparece en la query
                for tag in case_tags:
                    if tag.lower() in query_lower:
                        tag_bonus += 1

            total_score = overlap + (tag_bonus * 0.5)
            scored_cases.append((total_score, case))

    # Ordenar por score (descendente) y retornar top-k
    scored_cases.sort(reverse=True, key=lambda x: x[0])
    return [case for score, case in scored_cases[:top_k]]


def save_to_memory(query: str, solution: str, user_id: str, memory: Dict) -> str:
    """
    Guarda un nuevo caso en memoria persistente.

    La memoria se modifica in-place (dict mutable) para simular
    persistencia. En producciÃ³n, escribirÃ­as a una base de datos.

    Args:
        query: Consulta del usuario
        solution: SoluciÃ³n generada
        user_id: ID del usuario
        memory: Diccionario de memoria (modificado in-place)

    Returns:
        ID del caso guardado
    """
    # Inicializar lista de casos si no existe
    if "cases" not in memory:
        memory["cases"] = []

    # Generar ID Ãºnico
    case_id = f"case_{len(memory['cases']) + 1:03d}"

    # Crear entrada de caso
    new_case = {
        "id": case_id,
        "timestamp": datetime.datetime.now().isoformat(),
        "user_id": user_id,
        "query": query,
        "solution": solution,
        "tags": extract_tags(query + " " + solution),
        "success_count": 0,
        "last_used": datetime.datetime.now().isoformat()
    }

    # Agregar a memoria
    memory["cases"].append(new_case)

    return case_id


def extract_tags(text: str) -> List[str]:
    """
    Extrae tags relevantes de un texto.

    Usa keyword matching simple. En producciÃ³n, podrÃ­as usar:
    - NER (Named Entity Recognition)
    - LLM para extraer conceptos clave
    - ClasificaciÃ³n automÃ¡tica
    """
    # Keywords tÃ©cnicas comunes
    technical_keywords = {
        # Databases
        "database": "database",
        "bd": "database",
        "postgresql": "postgresql",
        "postgres": "postgresql",
        "mysql": "mysql",
        "mongodb": "mongodb",
        "sql": "sql",

        # Network
        "network": "network",
        "red": "network",
        "firewall": "firewall",
        "puerto": "port",
        "port": "port",
        "dns": "dns",
        "conectividad": "connectivity",
        "connectivity": "connectivity",

        # Security
        "security": "security",
        "seguridad": "security",
        "autenticacion": "authentication",
        "autenticaciÃ³n": "authentication",
        "authentication": "authentication",
        "auth": "authentication",
        "permisos": "permissions",
        "permissions": "permissions",
        "vulnerabilidad": "vulnerability",

        # Code
        "code": "code",
        "codigo": "code",
        "cÃ³digo": "code",
        "bug": "bug",
        "error": "error",
        "exception": "exception",

        # Web
        "api": "api",
        "rest": "rest",
        "http": "http",
        "https": "https",
        "ssl": "ssl",
        "tls": "tls",
        "certificado": "certificate",
        "certificate": "certificate"
    }

    text_lower = text.lower()
    found_tags = set()

    for keyword, tag in technical_keywords.items():
        if keyword in text_lower:
            found_tags.add(tag)

    return sorted(list(found_tags))


# =============================================================================
# AGENTES
# =============================================================================

def memory_agent(state: MemoryState) -> dict:
    """
    Agente que busca en memoria casos similares.

    Este agente implementa el primer paso del pattern:
    "Â¿Hemos visto algo similar antes?"

    Si encuentra casos similares, los prepara para que
    solution_agent los use como contexto.
    """
    print("\n" + "="*70)
    print("ðŸ§  MEMORY AGENT: Buscando casos similares...")
    print("="*70)

    query = state["query"]
    memory = state.get("memory", {"cases": []})

    print(f"   â†’ Memoria contiene {len(memory.get('cases', []))} casos totales")

    # Buscar casos similares
    similar_cases = search_similar_cases(query, memory, top_k=3)

    if similar_cases:
        print(f"   âœ“ Encontrados {len(similar_cases)} casos similares:")
        for i, case in enumerate(similar_cases, 1):
            print(f"      {i}. {case['id']}: {case['query'][:60]}...")
            if "tags" in case and case["tags"]:
                print(f"         Tags: {', '.join(case['tags'])}")
    else:
        print("   â„¹ No hay casos similares en memoria (caso nuevo)")

    return {"similar_cases": similar_cases}


def solution_agent(state: MemoryState) -> dict:
    """
    Agente que genera la soluciÃ³n usando contexto + memoria.

    Este agente es mÃ¡s efectivo cuando tiene acceso a casos similares:
    - Puede aprender de soluciones pasadas
    - Puede adaptar soluciones exitosas
    - Puede evitar errores previos

    La calidad de las soluciones mejora con el tiempo a medida
    que la memoria crece.
    """
    print("\nðŸ’¡ SOLUTION AGENT: Generando soluciÃ³n...")

    query = state["query"]
    similar_cases = state.get("similar_cases", [])

    # Construir contexto con casos similares
    similar_context = ""
    if similar_cases:
        similar_context = "\n\nCASOS SIMILARES RESUELTOS ANTERIORMENTE:\n"
        for i, case in enumerate(similar_cases, 1):
            similar_context += f"\n{i}. Problema: {case['query']}\n"
            similar_context += f"   SoluciÃ³n: {case['solution']}\n"
            if "success_count" in case and case["success_count"] > 0:
                similar_context += f"   Ã‰xitos: {case['success_count']}\n"
            if "tags" in case:
                similar_context += f"   Tags: {', '.join(case['tags'])}\n"

        print(f"   â†’ Usando {len(similar_cases)} caso(s) similar(es) como referencia")

    # Crear prompt adaptativo
    prompt = f"""Eres un especialista en soporte tÃ©cnico que aprende de experiencias pasadas.

CONSULTA ACTUAL:
{query}

{similar_context}

Genera una soluciÃ³n detallada y prÃ¡ctica para la consulta actual.

{"Si hay casos similares arriba, CONSIDERA esas soluciones como referencia, pero ADÃPTALAS especÃ­ficamente al problema actual. No copies textualmente, sino aprende de ellas." if similar_cases else "Este es un caso nuevo sin precedentes en la memoria. Genera una soluciÃ³n original y completa."}

La soluciÃ³n debe incluir:
1. DiagnÃ³stico del problema
2. Pasos especÃ­ficos para resolverlo
3. ExplicaciÃ³n de por quÃ© funciona
4. PrevenciÃ³n de problemas futuros

SOLUCIÃ“N DETALLADA:"""

    response = llm.invoke(prompt)
    solution = response.content

    # Decidir si guardar en memoria
    # Criterio: Siempre guardar para construir conocimiento
    # En producciÃ³n podrÃ­as:
    # - Solo guardar si es suficientemente diferente de casos existentes
    # - Solo guardar si el usuario confirma que funcionÃ³
    # - Solo guardar casos de cierta complejidad
    should_save = True

    print(f"   âœ“ SoluciÃ³n generada ({len(solution)} caracteres)")
    print(f"   â†’ Guardar en memoria: {'SÃ­' if should_save else 'No'}")

    return {
        "solution": solution,
        "should_save": should_save
    }


def update_memory_agent(state: MemoryState) -> dict:
    """
    Agente que actualiza la memoria con la nueva soluciÃ³n.

    Este agente implementa el aprendizaje del sistema:
    cada caso resuelto se convierte en conocimiento para el futuro.

    En producciÃ³n, este agente podrÃ­a:
    - Escribir a una base de datos
    - Generar embeddings y guardar en vector DB
    - Actualizar Ã­ndices de bÃºsqueda
    - Notificar a otros sistemas
    """
    print("\nðŸ’¾ UPDATE MEMORY: Actualizando memoria...")

    should_save = state.get("should_save", False)
    memory = state.get("memory", {"cases": []})

    if not should_save:
        print("   â„¹ Caso no guardado (no amerita memoria persistente)")
        return {}

    query = state["query"]
    solution = state["solution"]
    user_id = state.get("user_id", "unknown")

    # Guardar en memoria
    case_id = save_to_memory(query, solution, user_id, memory)

    print(f"   âœ“ Caso guardado: {case_id}")
    print(f"   â†’ Total de casos en memoria: {len(memory['cases'])}")

    return {}


# =============================================================================
# CONSTRUCCIÃ“N DEL GRAFO
# =============================================================================

def build_graph():
    """
    Construye el grafo con memoria compartida.

    Flujo lineal simple:
    1. memory_agent: Busca casos similares
    2. solution_agent: Genera soluciÃ³n (mejor si hay memoria)
    3. update_memory_agent: Guarda nuevo caso
    4. END

    La magia estÃ¡ en que 'memory' persiste entre invocaciones,
    permitiendo que el sistema aprenda continuamente.
    """
    workflow = StateGraph(MemoryState)

    # Agregar nodos
    workflow.add_node("memory", memory_agent)
    workflow.add_node("solution", solution_agent)
    workflow.add_node("update_memory", update_memory_agent)

    # Entry point
    workflow.set_entry_point("memory")

    # Flujo lineal
    workflow.add_edge("memory", "solution")
    workflow.add_edge("solution", "update_memory")
    workflow.add_edge("update_memory", END)

    return workflow.compile()


# =============================================================================
# EJECUCIÃ“N Y DEMO
# =============================================================================

def main():
    print("\n" + "="*70)
    print("ðŸ§  SISTEMA CON MEMORIA COMPARTIDA")
    print("="*70)
    print("\nEste sistema demuestra cÃ³mo los agentes aprenden de experiencias pasadas.")
    print("Observa cÃ³mo las soluciones mejoran a medida que se acumula conocimiento.\n")

    # Memoria compartida (simula persistencia)
    # En producciÃ³n, esto serÃ­a una base de datos
    shared_memory: Dict = {
        "cases": []
    }

    # Consultas de ejemplo que muestran aprendizaje
    queries = [
        ("user_001", "No puedo conectarme a la base de datos PostgreSQL, me da error de conexiÃ³n rechazada"),
        ("user_002", "Mi aplicaciÃ³n no puede acceder a PostgreSQL, dice connection refused"),
        ("user_001", "El servidor web no responde en el puerto 443, creo que es un problema de certificado SSL"),
        ("user_003", "Error de conexiÃ³n a la base de datos, no sÃ© quÃ© hacer"),
        ("user_004", "El certificado SSL expirÃ³ y ahora no puedo acceder al servidor HTTPS"),
    ]

    app = build_graph()

    for i, (user_id, query) in enumerate(queries, 1):
        print(f"\n{'='*70}")
        print(f"ðŸ“‹ CONSULTA {i}/5 (Usuario: {user_id}):")
        print(f"{'='*70}")
        print(f"{query}")

        initial_state = {
            "query": query,
            "user_id": user_id,
            "similar_cases": [],
            "solution": "",
            "should_save": False,
            "memory": shared_memory  # Â¡El mismo diccionario compartido!
        }

        # Ejecutar grafo
        final_state = app.invoke(initial_state)

        print("\n" + "="*70)
        print("ðŸ“Š SOLUCIÃ“N GENERADA")
        print("="*70)
        print(final_state["solution"])

        # Mostrar estado de memoria despuÃ©s de cada consulta
        print(f"\nðŸ“ˆ Estado de memoria despuÃ©s de consulta {i}:")
        print(f"   â€¢ Total de casos guardados: {len(shared_memory['cases'])}")

        if shared_memory["cases"]:
            print(f"   â€¢ Casos recientes:")
            for case in shared_memory["cases"][-min(3, len(shared_memory['cases'])):]:
                print(f"      - {case['id']}: {case['query'][:50]}...")
                if case.get("tags"):
                    print(f"        Tags: {', '.join(case['tags'])}")

        if i < len(queries):
            input("\n[Presiona Enter para la siguiente consulta...]")

    # Mostrar anÃ¡lisis final de memoria
    print("\n" + "="*70)
    print("ðŸ“š ANÃLISIS FINAL DE MEMORIA")
    print("="*70)

    print(f"\nTotal de casos guardados: {len(shared_memory['cases'])}")

    # EstadÃ­sticas de tags
    all_tags = {}
    for case in shared_memory["cases"]:
        for tag in case.get("tags", []):
            all_tags[tag] = all_tags.get(tag, 0) + 1

    if all_tags:
        print("\nðŸ“Š Temas mÃ¡s comunes (por tags):")
        sorted_tags = sorted(all_tags.items(), key=lambda x: x[1], reverse=True)
        for tag, count in sorted_tags[:5]:
            print(f"   â€¢ {tag}: {count} casos")

    # Usuarios mÃ¡s activos
    user_counts = {}
    for case in shared_memory["cases"]:
        user = case["user_id"]
        user_counts[user] = user_counts.get(user, 0) + 1

    print("\nðŸ‘¥ Usuarios mÃ¡s activos:")
    sorted_users = sorted(user_counts.items(), key=lambda x: x[1], reverse=True)
    for user, count in sorted_users:
        print(f"   â€¢ {user}: {count} consultas")

    # Mostrar todos los casos
    print("\nðŸ“ Detalle de todos los casos guardados:")
    for case in shared_memory["cases"]:
        print(f"\n{case['id']} - {case['timestamp']}")
        print(f"   Usuario: {case['user_id']}")
        print(f"   Query: {case['query'][:80]}...")
        print(f"   Solution: {case['solution'][:100]}...")
        print(f"   Tags: {', '.join(case.get('tags', []))}")

    print("\n" + "="*70)
    print("ðŸŽ‰ Â¡Ejercicio completado!")
    print("="*70)
    print("\nðŸ’¡ Observaciones sobre Memoria Compartida:")
    print("   â€¢ La memoria permite aprendizaje acumulativo")
    print("   â€¢ Cada caso resuelto mejora las futuras soluciones")
    print("   â€¢ Los casos similares aceleran la resoluciÃ³n")
    print("   â€¢ El sistema se vuelve mÃ¡s inteligente con el uso")
    print("   â€¢ En producciÃ³n: usar vector DB para bÃºsqueda semÃ¡ntica")
    print("\nðŸš€ PrÃ³ximos pasos:")
    print("   â€¢ Implementar embeddings para bÃºsqueda semÃ¡ntica")
    print("   â€¢ Agregar rating de soluciones por usuarios")
    print("   â€¢ Implementar memory pruning (limpiar casos obsoletos)")
    print("   â€¢ Detectar patrones comunes automÃ¡ticamente")


if __name__ == "__main__":
    main()
